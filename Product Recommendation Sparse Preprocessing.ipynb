{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmkfRu5134RF"
   },
   "source": [
    "# Product Recommendation Sparse Preprocessing\n",
    "Reference: [https://ieeexplore.ieee.org/document/5430993](https://www2.seas.gwu.edu/~simhaweb/champalg/cf/papers/wroberts.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJuzA-4gDOlk",
    "outputId": "920a8722-c339-43be-8150-9821bfc686e8"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS5apXib34RG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops import *\n",
    "from tensorflow.raw_ops import SparseMatrixAdd, SparseMatrixMatMul, SparseMatrixSparseMatMul, SparseMatrixZeros\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ar29zUBM34RK",
    "outputId": "f18383b5-01ca-4d68-e87f-e518c7dbacfc"
   },
   "outputs": [],
   "source": [
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gt49E_ALZ3GX",
    "outputId": "10b46376-85ff-4f3c-97d0-bb55f0b1207f"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T5Q0rW_CfY-",
    "outputId": "8587de2f-dc8b-4254-ffca-ebcea876f9c0"
   },
   "outputs": [],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHkz4VQV34RO"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GX0q_If34RO"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Y_data = pd.read_csv('data/Y.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "# P_data = pd.read_csv('data/P.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)\n",
    "\n",
    "Y_data = pd.read_csv('data/Y_full.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "P_data = pd.read_csv('data/P_full.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "jIElYz6n34RR",
    "outputId": "2554f79e-4439-4b71-ba69-9163832f3710"
   },
   "outputs": [],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVHMQ8gY34RU",
    "outputId": "745276ed-b01f-4c7c-ed25-001053e04e22"
   },
   "outputs": [],
   "source": [
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCmeGkgl34RX",
    "outputId": "53ae3fa2-d868-4e63-e7bd-f8131891afc1"
   },
   "outputs": [],
   "source": [
    "print(Y_data['Rating'].max(), Y_data['Movie'].max(), Y_data['User'].max())\n",
    "print(P_data['Rating'].max(), P_data['Movie'].max(), P_data['User'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_80ytphB34Ra",
    "outputId": "5f36038e-f15f-4cac-af13-0ee46ad545c2"
   },
   "outputs": [],
   "source": [
    "k, n = Y_data['Movie'].max(), Y_data['User'].max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW57mVdqCfZN"
   },
   "outputs": [],
   "source": [
    "def generate_indices_pair_list(data):\n",
    "    user_id = 1\n",
    "    indices_list = list()\n",
    "    for index, row in enumerate(tqdm(data, total=data.shape[0])):\n",
    "        if row[2] != user_id:\n",
    "            user_id = row[2]\n",
    "            indices_list.append((user_id - 1, index - 1))\n",
    "    indices_list.append((user_id, index)) # append the last user id and ending index pair\n",
    "\n",
    "    indices_pair_list = list()\n",
    "    for (user_id, index_ending) in indices_list:\n",
    "        if index_ending == indices_list[0][1]: # if the first ending index\n",
    "            indices_pair_list.append((1, 0, index_ending))\n",
    "        else:\n",
    "            index_beginning = indices_pair_list[-1][2] + 1\n",
    "            indices_pair_list.append((user_id, index_beginning, index_ending))\n",
    "    return indices_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXhR9fwaoJXo",
    "outputId": "f1e8bfe8-0c08-4908-936d-977289329b96"
   },
   "outputs": [],
   "source": [
    "Y_data = Y_data.values\n",
    "P_data = P_data.values\n",
    "\n",
    "indices_pair_list_Y_data = generate_indices_pair_list(Y_data)\n",
    "indices_pair_list_P_data = generate_indices_pair_list(P_data)\n",
    "len(indices_pair_list_Y_data) == len(indices_pair_list_P_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "706NDFE1CfZR"
   },
   "outputs": [],
   "source": [
    "user_id_indices_pair_dict_P_data = dict()\n",
    "for (user_id, index_beginning, index_ending) in indices_pair_list_P_data:\n",
    "    user_id_indices_pair_dict_P_data[user_id] = (index_beginning, index_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUBYeVaK34Rt",
    "outputId": "0a8310a3-8741-4f6b-e8f2-7eaac4a265da"
   },
   "outputs": [],
   "source": [
    "def _float_feature(tensor):\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        value = tensor.flatten()\n",
    "    else:\n",
    "        value = tensor.numpy().flatten()\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _sparse_feature(sparse_tensor):\n",
    "    value = tf.io.serialize_sparse(sparse_tensor).numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "filename = 'data/data_preprocessed.tfrecord'\n",
    "with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for index_pair_Y_data in tqdm(indices_pair_list_Y_data, total=len(indices_pair_list_Y_data)):\n",
    "        t = index_pair_Y_data[0]\n",
    "        Y_data_t = Y_data[index_pair_Y_data[1]:index_pair_Y_data[2]+1, :]\n",
    "\n",
    "        movie_ids_t_indices = (Y_data_t[:, 1] - 1).astype(np.int64)\n",
    "        movie_ids_t_indices_deleted = np.setdiff1d(np.arange(k, dtype=np.int64), movie_ids_t_indices)\n",
    "\n",
    "        H_yt_st_indices = np.vstack((np.arange(movie_ids_t_indices.shape[0]), movie_ids_t_indices)).T\n",
    "        H_xt_st_indices = np.vstack((np.arange(movie_ids_t_indices_deleted.shape[0]), movie_ids_t_indices_deleted)).T\n",
    "        z_t_st_indices = np.vstack((movie_ids_t_indices, np.zeros(movie_ids_t_indices.shape[0], dtype=np.int64))).T\n",
    "\n",
    "        H_yt_st = tf.SparseTensor(indices=H_yt_st_indices, values=np.ones(H_yt_st_indices.shape[0], dtype=np.float32), dense_shape=[H_yt_st_indices.shape[0], k])\n",
    "        H_xt_st = tf.SparseTensor(indices=H_xt_st_indices, values=np.ones(H_xt_st_indices.shape[0], dtype=np.float32), dense_shape=[H_xt_st_indices.shape[0], k])\n",
    "        z_t_st = tf.SparseTensor(indices=z_t_st_indices, values=Y_data_t[:, 0].astype(np.float32), dense_shape=[k, 1])\n",
    "\n",
    "        H_yt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_yt_st.indices, values=H_yt_st.values, dense_shape=H_yt_st.dense_shape)\n",
    "        H_xt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_xt_st.indices, values=H_xt_st.values, dense_shape=H_xt_st.dense_shape)\n",
    "        z_t_sm = sparse_tensor_to_csr_sparse_matrix(indices=z_t_st.indices, values=z_t_st.values, dense_shape=z_t_st.dense_shape)\n",
    "\n",
    "        y_t_sm = SparseMatrixSparseMatMul(a=H_yt_sm, b=z_t_sm, type=tf.float32)\n",
    "        y_t = csr_sparse_matrix_to_dense(y_t_sm, tf.float32)\n",
    "        k_t = tf.constant(H_yt_st_indices.shape[0], dtype=tf.float32)\n",
    "        \n",
    "        if t in user_id_indices_pair_dict_P_data:\n",
    "            index_beginning, index_ending = user_id_indices_pair_dict_P_data[t]\n",
    "            P_data_t = P_data[index_beginning:index_ending+1, :]\n",
    "            movie_ids_t_P_data_feature = _float_feature(P_data_t[:, 1])\n",
    "            ratings_t_P_data_feature = _float_feature(tf.expand_dims(P_data_t[:, 0].astype(np.float32), axis=1))\n",
    "        else:\n",
    "            movie_ids_t_P_data_feature = _float_feature(np.array([999.999]))\n",
    "            ratings_t_P_data_feature = _float_feature(np.array([999.999]))\n",
    "            \n",
    "        feature = {\n",
    "                'H_yt_st': _sparse_feature(H_yt_st),\n",
    "                'H_xt_st': _sparse_feature(H_xt_st),\n",
    "                'y_t': _float_feature(y_t),\n",
    "                'k_t': _float_feature(k_t),\n",
    "                'movie_ids_t_P_data': movie_ids_t_P_data_feature,\n",
    "                'ratings_t_P_data': ratings_t_P_data_feature,\n",
    "        }\n",
    "        writer.write(tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y_data\n",
    "del P_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2reL7Zyx34R4"
   },
   "source": [
    "## Initialization\n",
    "\n",
    "$\\mu$ has 1 type available\n",
    "\n",
    "$N = \\sum_{t=1}^{n}H_{y_t}'H_{y_t}$\n",
    "\n",
    "$\\hat{\\mu}^0 = N^{-1}\\sum_{t-1}^{n}H_{y_t}'y_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GXz93Hq34R7",
    "outputId": "ee7f4cc3-a9f1-408e-de62-4acc088aa966"
   },
   "outputs": [],
   "source": [
    "# initial estimate of mu\n",
    "N_sm = SparseMatrixZeros(dense_shape=(k, k), type=tf.float32)\n",
    "H_yty_t = 0\n",
    "\n",
    "for features_parsed in tqdm(data_preprocessed, total=len(indices_pair_list_Y_data)):\n",
    "    H_yt_st, y_t = features_parsed['H_yt_st'], features_parsed['y_t']\n",
    "    H_yt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_yt_st.indices, values=H_yt_st.values, dense_shape=H_yt_st.dense_shape)\n",
    "    \n",
    "    N_sm = SparseMatrixAdd(a=N_sm, b=SparseMatrixSparseMatMul(a=H_yt_sm, b=H_yt_sm, type=tf.float32, transpose_a=True), alpha=1.0, beta=1.0)\n",
    "    H_yty_t += SparseMatrixMatMul(a=H_yt_sm, b=y_t, transpose_a=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIVUEfFNKmWo",
    "outputId": "dec7f99c-d2a0-465c-c68b-966e68e0cb6f"
   },
   "outputs": [],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N_inv = tf.linalg.inv(csr_sparse_matrix_to_dense(N_sm, tf.float32))\n",
    "mu_hat0 = tf.matmul(N_inv, H_yty_t)\n",
    "tf.transpose(mu_hat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vja1fJxr34SL"
   },
   "source": [
    "R has 4 types available\n",
    "\n",
    "$R_{1} = I$\n",
    "\n",
    "$R_{2} = N^{-1}diag(S)$\n",
    "\n",
    "$R_{3} = diag(S)^{-1/2}Sdiag(S)^{-1/2}$\n",
    "\n",
    "$R_{4} = N^{-1/2}SN^{-1/2}$\n",
    "\n",
    "where $S = \\sum_{t=1}^{n}H_{y_{t}}'(y_t - H_{y_{t}}\\hat{\\mu}^0)(y_t - H_{y_{t}}\\hat{\\mu}^0)'H_{y_{t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "hCmQxlgc34SL",
    "outputId": "bbff4626-553c-4429-dd74-adb55359203e"
   },
   "outputs": [],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.eye(k, dtype=tf.float32)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aKGDb-C3tZZI",
    "outputId": "7a45cd6e-e163-490c-e492-3c8802108dea"
   },
   "outputs": [],
   "source": [
    "S = 0\n",
    "for features_parsed in tqdm(data_preprocessed, total=len(indices_pair_list_Y_data)):\n",
    "    H_yt_st y_t = features_parsed['H_yt_st'], features_parsed['y_t']\n",
    "    H_yt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_yt_st.indices, values=H_yt_st.values, dense_shape=H_yt_st.dense_shape)\n",
    "    \n",
    "    Hytmu_hat0 = SparseMatrixMatMul(a=H_yt_sm, b=mu_hat0)\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=y_t - Hytmu_hat0, transpose_a=True)\n",
    "    S += tf.matmul(intermediate_result, intermediate_result, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "wDgAbOwV34SW",
    "outputId": "e7f7266f-ec32-4056-a405-5daa14885c05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(N_inv, diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "z59PFlrGOaNI",
    "outputId": "28dd86e6-5cac-4f41-eb93-df9ef6fca588"
   },
   "outputs": [],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "diag_S_inv_sqrtm = tf.linalg.sqrtm(tf.linalg.inv(diag_S))\n",
    "R_hat0_3 = diag_S_inv_sqrtm @ S @ diag_S_inv_sqrtm\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "E1VHBBE8OGN7",
    "outputId": "fb53d9bc-3bc9-4f4c-e099-503dd198b916"
   },
   "outputs": [],
   "source": [
    "# R_hat0_4 = tf.matmul(tf.linalg.sqrtm(N_inv), tf.matmul(S, tf.linalg.sqrtm(N_inv)))\n",
    "N_inv_sqrtm = tf.linalg.sqrtm(N_inv)\n",
    "R_hat0_4 = N_inv_sqrtm @ S @ N_inv_sqrtm\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mu_hat0.npy', mu_hat0)\n",
    "np.save('R_hat0_4.npy', R_hat0_4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Product Recommendation Sparse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
