{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmkfRu5134RF"
   },
   "source": [
    "# Product Recommendation Training and Evaluation\n",
    "Reference: [https://ieeexplore.ieee.org/document/5430993](https://www2.seas.gwu.edu/~simhaweb/champalg/cf/papers/wroberts.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FS5apXib34RG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops import *\n",
    "from tensorflow.raw_ops import SparseMatrixAdd, SparseMatrixMatMul, SparseMatrixSparseMatMul, SparseMatrixZeros\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ar29zUBM34RK",
    "outputId": "f18383b5-01ca-4d68-e87f-e518c7dbacfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gt49E_ALZ3GX",
    "outputId": "10b46376-85ff-4f3c-97d0-bb55f0b1207f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 29 01:05:15 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   44C    P0    38W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   47C    P0    37W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   47C    P0    40W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   44C    P0    40W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T5Q0rW_CfY-",
    "outputId": "8587de2f-dc8b-4254-ffca-ebcea876f9c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                32\n",
      "On-line CPU(s) list:   0-31\n",
      "Thread(s) per core:    2\n",
      "Core(s) per socket:    16\n",
      "Socket(s):             1\n",
      "NUMA node(s):          1\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 79\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
      "Stepping:              1\n",
      "CPU MHz:               2665.895\n",
      "CPU max MHz:           3000.0000\n",
      "CPU min MHz:           1200.0000\n",
      "BogoMIPS:              4600.00\n",
      "Hypervisor vendor:     Xen\n",
      "Virtualization type:   full\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              46080K\n",
      "NUMA node0 CPU(s):     0-31\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, n = 17770, 480189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(data_element_serialized):    \n",
    "    features = {\n",
    "        'H_yt_st': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "        'H_xt_st': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "        'y_t': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "        'k_t': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "        'movie_ids_t_P_data': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "        'ratings_t_P_data': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    }\n",
    "    \n",
    "    features_parsed = tf.io.parse_single_example(serialized=data_element_serialized, features=features)\n",
    "    \n",
    "    # tf.io.deserialize_many_sparse() requires the dimensions to be [batch_size, 3], so we add an additional dimension, which will be removed later\n",
    "    H_yt_st = tf.io.deserialize_many_sparse(tf.expand_dims(features_parsed['H_yt_st'], axis=0), dtype=tf.float32)\n",
    "    H_xt_st = tf.io.deserialize_many_sparse(tf.expand_dims(features_parsed['H_xt_st'], axis=0), dtype=tf.float32)\n",
    "    features_parsed['H_yt_st'] = tf.sparse.reshape(H_yt_st, tf.shape(H_yt_st)[1:])\n",
    "    features_parsed[\"H_xt_st\"] = tf.sparse.reshape(H_xt_st, tf.shape(H_xt_st)[1:])\n",
    "    features_parsed['y_t'] = tf.expand_dims(features_parsed['y_t'], axis=1)\n",
    "    features_parsed['k_t'] = tf.expand_dims(features_parsed['k_t'], axis=1)\n",
    "    features_parsed['movie_ids_t_P_data'] = features_parsed['movie_ids_t_P_data']\n",
    "    features_parsed['ratings_t_P_data'] = tf.expand_dims(features_parsed['ratings_t_P_data'], axis=1)\n",
    "    return features_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = tf.data.TFRecordDataset(['data/data_preprocessed.tfrecord']).map(parse_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 390 ms, sys: 1.06 s, total: 1.45 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu_hat0 = tf.constant(np.load('mu_hat0.npy'), tf.float32)\n",
    "R_hat0_4 = tf.constant(np.load('R_hat0_4.npy'), tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McMichaelâ€™s Algorithm\n",
    "\n",
    "1. $\\hat{R}^{i+1} = \\hat{R}^{i} + \\gamma \\hat{R}^{i} \\bigg(\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} \\bigg) \\hat{R}^{i}$ <br />\n",
    "where $\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} = -\\frac{1}{2} \\sum_{t=1}^{n} H_{y_t}' \\Big(\\big(R_{y_t}^{i}\\big)^{-1} - \\big(R_{y_t}^{i}\\big)^{-1} (y_t - \\mu_{y_t}) (y_t - \\mu_{y_t})' \\big(R_{y_t}^{i}\\big)^{-1}\\Big) H_{y_t}$\n",
    "\n",
    "2. $\\hat{\\mu} = \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}H_{y_t}\\big)^{-1} \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}y_t\\big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5E-PMb4w34Se"
   },
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "    \n",
    "    for features_parsed in tqdm(data_preprocessed, total=n):\n",
    "        H_yt_st, y_t, k_t = features_parsed['H_yt_st'], features_parsed['y_t'], features_parsed['k_t']\n",
    "        \n",
    "        with tf.device('/GPU:0'):\n",
    "            H_yt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_yt_st.indices, values=H_yt_st.values, dense_shape=H_yt_st.dense_shape)\n",
    "            # for R estimation\n",
    "            # R_yt = H_yt @ R @ H_yt_trans\n",
    "            R_yt = SparseMatrixMatMul(a=H_yt_sm, b=SparseMatrixMatMul(a=H_yt_sm, b=R), transpose_b=True, transpose_output=True)\n",
    "            R_yt_inv = tf.linalg.inv(R_yt)\n",
    "            yt_minus_mu_yt = y_t - SparseMatrixMatMul(a=H_yt_sm, b=mu)\n",
    "\n",
    "            # for log likelihood calculation\n",
    "            log_p_hat_part = -1/2*(tf.math.log(tf.linalg.det(R_yt)) + tf.transpose(yt_minus_mu_yt) @ R_yt_inv @ (yt_minus_mu_yt) + k_t*LOG_2PI)\n",
    "            log_p_hat += log_p_hat_part\n",
    "        \n",
    "        with tf.device('/GPU:1'):\n",
    "            # for R estimation\n",
    "            # log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "            intermediate_result = R_yt_inv @ yt_minus_mu_yt\n",
    "            intermediate_result_2 = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv - tf.matmul(intermediate_result, intermediate_result, transpose_b=True), transpose_a=True)\n",
    "            log_p_gradient_part = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result_2, transpose_a=True, transpose_b=True, transpose_output=True)\n",
    "            log_p_gradient += log_p_gradient_part\n",
    "        \n",
    "        \n",
    "        with tf.device('/GPU:2'):\n",
    "            # for mu estimation\n",
    "            # Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "            Hyt_trans_Ryt_inv_Hyt_sum_part = SparseMatrixMatMul(a=H_yt_sm, b=SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv, transpose_a=True, transpose_b=True, transpose_output=True), transpose_a=True)\n",
    "            # Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "            Hyt_trans_Ryt_inv_yt_sum_part = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv @ y_t, transpose_a=True)\n",
    "            Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        \n",
    "        \n",
    "        with tf.device('/GPU:3'):\n",
    "            Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "\n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlwupDTDQ1_u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/480189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 427476/480189 [3:29:56<23:54, 36.74it/s]  "
     ]
    }
   ],
   "source": [
    "# delta = 0.0005\n",
    "delta = 0.2\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float32)\n",
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float32))\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print(f'normalized log_p_hat: {(log_p_hat/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'normalized log_p:     {(log_p/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'convergence gap:      {(log_p_hat/n - log_p/n).numpy().flatten()[0]:.5}')\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOaC9y5W34Si"
   },
   "outputs": [],
   "source": [
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTe3igOD34St"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "$\\epsilon^2 = \\frac{\\sum_{t=1}^{n}\\big(x_t - \\hat{X_t}\\big)'\\big(x_t - \\hat{X_t}\\big)}{\\sum_{t=1}^{n} l_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt_sm, H_yt_sm):\n",
    "    # calculate X_t_hat\n",
    "    # R_xt = H_xt @ R @ H_xt_trans\n",
    "    # R_yt = H_yt @ R @ H_yt_trans\n",
    "    # R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    # R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    # mu_yt = tf.matmul(H_yt, mu)\n",
    "    # mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_xt_sm, b=R)\n",
    "    R_xt = SparseMatrixMatMul(a=H_xt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "    \n",
    "    intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=R)\n",
    "    R_yt = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_xt_sm, b=R)\n",
    "    R_xtyt = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "\n",
    "    mu_yt = SparseMatrixMatMul(a=H_yt_sm, b=mu)\n",
    "    mu_xt = SparseMatrixMatMul(a=H_xt_sm, b=mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    \n",
    "    # clip ratings\n",
    "    # predictions_t = tf.gather(tf.matmul(H_xt_trans, X_t_hat), indices=movie_ids_t-1)\n",
    "    predictions_t = tf.gather(SparseMatrixMatMul(a=H_xt_sm, b=X_t_hat, transpose_a=True), indices=movie_ids_t_P_data-1)\n",
    "    predictions_t = tf.clip_by_value(predictions_t, 1, 5)\n",
    "    \n",
    "    return tf.matmul(tf.transpose(ratings_t_P_data - predictions_t), ratings_t_P_data - predictions_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for (H_yt_sm, H_xt_sm, y_t, k_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        if movie_ids_t_P_data is not None:\n",
    "            square_error += run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt_sm, H_yt_sm)\n",
    "            l += len(ratings_t_P_data)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Product Recommendation Sparse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
