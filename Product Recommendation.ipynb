{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation\n",
    "Reference: https://ieeexplore.ieee.org/document/5430993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = pd.read_csv('data/Y.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "P_data = pd.read_csv('data/P.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       5      2     1\n",
       "1       4      7     1\n",
       "2       4      8     1\n",
       "3       4     11     1\n",
       "4       4     12     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       3      6     1\n",
       "1       5     96     1\n",
       "2       3      1     2\n",
       "3       3     33     3\n",
       "4       5     42     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((3399874, 3), (189699, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())\n",
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100 137328\n",
      "5 100 137328\n"
     ]
    }
   ],
   "source": [
    "print(Y_data['Rating'].max(), Y_data['Movie'].max(), Y_data['User'].max())\n",
    "print(P_data['Rating'].max(), P_data['Movie'].max(), P_data['User'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 137328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = Y_data['Movie'].max(), Y_data['User'].max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices_pair_list(data):\n",
    "    user_id = 1\n",
    "    indices_list = list()\n",
    "    for index, row in enumerate(tqdm(data, total=data.shape[0])):\n",
    "        if row[2] != user_id:\n",
    "            user_id = row[2]\n",
    "            indices_list.append((user_id - 1, index - 1))\n",
    "    indices_list.append((user_id, index)) # append the last user id and ending index pair\n",
    "\n",
    "    indices_pair_list = list()\n",
    "    for (user_id, index_ending) in indices_list:\n",
    "        if index_ending == indices_list[0][1]: # if the first ending index\n",
    "            indices_pair_list.append((1, 0, index_ending))\n",
    "        else:\n",
    "            index_beginning = indices_pair_list[-1][2] + 1\n",
    "            indices_pair_list.append((user_id, index_beginning, index_ending))\n",
    "    return indices_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3399874/3399874 [00:02<00:00, 1467602.21it/s]\n",
      "100%|██████████| 189699/189699 [00:00<00:00, 365474.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data = Y_data.values\n",
    "P_data = P_data.values\n",
    "\n",
    "indices_pair_list_Y_data = generate_indices_pair_list(Y_data)\n",
    "indices_pair_list_P_data = generate_indices_pair_list(P_data)\n",
    "len(indices_pair_list_Y_data) == len(indices_pair_list_P_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1644.25it/s]\n"
     ]
    }
   ],
   "source": [
    "data_preprocessed = list()\n",
    "for index_pair_Y_data, index_pair_P_data in tqdm(zip(indices_pair_list_Y_data, indices_pair_list_P_data), total=len(indices_pair_list_Y_data)):\n",
    "    Y_data_t = Y_data[index_pair_Y_data[1]:index_pair_Y_data[2]+1, :]\n",
    "    \n",
    "    movie_ids_t_indices = Y_data_t[:, 1] - 1    \n",
    "    H_yt = tf.constant(np.identity(k)[movie_ids_t_indices], dtype=tf.float32)\n",
    "    H_xt = tf.constant(np.delete(np.identity(k), movie_ids_t_indices, 0), dtype=tf.float32)    \n",
    "    k_t = tf.constant(H_yt.shape[0], dtype=tf.float32)\n",
    "    \n",
    "    z_t_st_indices = np.vstack((movie_ids_t_indices, np.zeros(movie_ids_t_indices.shape[0], dtype=np.int64))).T\n",
    "    z_t = tf.sparse.to_dense(tf.SparseTensor(indices=z_t_st_indices, values=Y_data_t[:, 0].astype(np.float32), dense_shape=[k, 1]))\n",
    "    \n",
    "    y_t = tf.matmul(H_yt, z_t)\n",
    "    \n",
    "    P_data_t = P_data[index_pair_P_data[1]:index_pair_P_data[2]+1, :]\n",
    "    movie_ids_t_P_data = P_data_t[:, 1]\n",
    "    ratings_t_P_data = tf.expand_dims(P_data_t[:, 0].astype(np.float32), axis=1)\n",
    "    data_preprocessed.append((H_yt, H_xt, tf.transpose(H_yt), tf.transpose(H_xt), k_t, y_t, movie_ids_t_P_data, ratings_t_P_data))\n",
    "        \n",
    "del Y_data\n",
    "del P_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "$\\mu$ has 1 type available\n",
    "\n",
    "$N = \\sum_{t=1}^{n}H_{y_t}'H_{y_t}$\n",
    "\n",
    "$\\hat{\\mu}^0 = N^{-1}\\sum_{t-1}^{n}H_{y_t}'y_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:09<00:00, 14233.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# initial estimate of mu\n",
    "N = 0\n",
    "H_yty_t = 0\n",
    "    \n",
    "for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, y_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "    N += tf.matmul(H_yt_trans, H_yt)\n",
    "    H_yty_t += tf.matmul(H_yt_trans, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[20017.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0., 23917.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0.,     0., 31634., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [    0.,     0.,     0., ..., 60896.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0., 61521.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0., 64506.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
       "array([[3.4526653, 3.5767446, 3.2878866, 3.9047875, 3.7903547, 3.4441562,\n",
       "        3.1907156, 4.5283504, 3.8201375, 3.6159503, 3.4038272, 3.8372512,\n",
       "        4.076039 , 4.228367 , 3.3539548, 4.0645275, 3.7211962, 3.4870086,\n",
       "        4.1638894, 3.4098244, 3.86926  , 3.435835 , 3.2032444, 4.084879 ,\n",
       "        3.2319984, 3.886648 , 4.331895 , 4.3835816, 4.316387 , 3.8659174,\n",
       "        4.339757 , 3.8914788, 3.7002926, 3.3624778, 4.3290153, 4.0670686,\n",
       "        4.56922  , 3.771041 , 3.6858668, 3.8453238, 4.3454113, 3.9099922,\n",
       "        3.3994992, 3.607868 , 3.962671 , 4.143861 , 3.4072049, 3.7040226,\n",
       "        4.0035033, 4.6428022, 3.216233 , 3.7723858, 4.265651 , 4.453773 ,\n",
       "        3.8384895, 3.793742 , 3.762917 , 3.886986 , 3.8004174, 4.34697  ,\n",
       "        3.8046958, 3.8462481, 3.641226 , 3.2722168, 3.4233348, 3.7163155,\n",
       "        3.2069893, 4.4541044, 4.265413 , 3.8610919, 4.483009 , 4.3621464,\n",
       "        3.5388138, 4.1171074, 3.8946984, 3.3607926, 4.1794305, 3.5793724,\n",
       "        3.6397824, 3.9759395, 3.7507348, 3.8211102, 4.0340624, 3.958301 ,\n",
       "        3.4913766, 3.4741971, 3.821479 , 3.6429584, 3.4742856, 3.6389375,\n",
       "        3.4526339, 3.504761 , 4.367291 , 4.3617887, 4.0115166, 4.192395 ,\n",
       "        3.480681 , 3.8585622, 3.802588 , 3.3873746]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_hat0 = tf.matmul(tf.linalg.inv(N), H_yty_t)\n",
    "tf.transpose(mu_hat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R has 4 types available\n",
    "\n",
    "$R_{1} = I$\n",
    "\n",
    "$R_{2} = N^{-1}diag(S)$\n",
    "\n",
    "$R_{3} = diag(S)^{-1/2}Sdiag(S)^{-1/2}$\n",
    "\n",
    "$R_{4} = N^{-1/2}SN^{-1/2}$\n",
    "\n",
    "where $S = \\sum_{t=1}^{n}H_{y_{t}}'(y_t - H_{y_{t}}\\hat{\\mu}^0)(y_t - H_{y_{t}}\\hat{\\mu}^0)'H_{y_{t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.eye(k, dtype=tf.float32)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:19<00:00, 7185.78it/s]\n"
     ]
    }
   ],
   "source": [
    "S = 0\n",
    "for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, y_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "    Hytmu_hat0 = tf.matmul(H_yt, mu_hat0)\n",
    "    S += H_yt_trans @ (y_t - Hytmu_hat0) @ tf.transpose(y_t - Hytmu_hat0) @ H_yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[1.724364  , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.94215506, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.4365153 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.1832098 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.0349715 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.2620207 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "N_inv = tf.linalg.inv(N)\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(N_inv, diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[ 1.        ,  0.07418474, -0.01158332, ..., -0.01462824,\n",
       "        -0.02215266, -0.01845053],\n",
       "       [ 0.07418475,  1.        ,  0.03674483, ...,  0.02561698,\n",
       "         0.03563043,  0.03926769],\n",
       "       [-0.01158332,  0.03674483,  0.9999999 , ...,  0.10954399,\n",
       "         0.12823027,  0.1556249 ],\n",
       "       ...,\n",
       "       [-0.01462824,  0.02561698,  0.10954399, ...,  1.        ,\n",
       "         0.19780062,  0.15164363],\n",
       "       [-0.02215266,  0.03563043,  0.12823027, ...,  0.19780062,\n",
       "         1.0000001 ,  0.18997027],\n",
       "       [-0.01845053,  0.03926768,  0.1556249 , ...,  0.15164362,\n",
       "         0.18997027,  1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "diag_S_inv = tf.linalg.inv(diag_S)\n",
    "R_hat0_3 = tf.linalg.sqrtm(diag_S_inv) @ S @ tf.linalg.sqrtm(diag_S_inv)\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[ 1.724364  ,  0.09455624, -0.01823068, ..., -0.02089477,\n",
       "        -0.02959406, -0.02721802],\n",
       "       [ 0.09455624,  0.94215494,  0.04274768, ...,  0.02704705,\n",
       "         0.03518409,  0.04281832],\n",
       "       [-0.01823068,  0.04274768,  1.4365153 , ...,  0.14281526,\n",
       "         0.15635432,  0.20954023],\n",
       "       ...,\n",
       "       [-0.02089477,  0.02704705,  0.14281526, ...,  1.1832099 ,\n",
       "         0.21888837,  0.18530548],\n",
       "       [-0.02959407,  0.03518409,  0.15635432, ...,  0.21888836,\n",
       "         1.0349715 ,  0.2171116 ],\n",
       "       [-0.02721801,  0.04281832,  0.20954023, ...,  0.18530548,\n",
       "         0.2171116 ,  1.2620206 ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat0_4 = tf.linalg.sqrtm(N_inv) @ S @ tf.linalg.sqrtm(N_inv)\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization Algorithm\n",
    "\n",
    "1. $\\hat{R}^{i+1} = \\frac{1}{n} \\sum_{t=1}^{n} (\\hat{Z}_t - \\mu)(\\hat{Z}_t - \\mu)' + H_{x_t}' \\bigg(\\hat{R}_{x_t}^{i} - \\hat{R}_{x_ty_t}^{i} \\big(\\hat{R}_{y_t}^{i}\\big)^{-1} \\big(\\hat{R}_{x_ty_t}^{i}\\big)'\\bigg) H_{x_t}$ <br />\n",
    "where <br />\n",
    "$\\hat{Z} = H_{y_t}'y_t + H_{x_t}'\\hat{X_t}$ <br />\n",
    "$\\hat{X_t} = R_{x_ty_t} R_{y_t}^{-1} (y_t - \\mu_{y_t}) + \\mu_{x_t}$ <br />\n",
    "$R_{x_t} = H_{x_t} R H_{x_t}'$ <br />\n",
    "$R_{y_t} = H_{y_t} R H_{y_t}'$ <br />\n",
    "$R_{x_ty_t} = H_{x_t}RH_{y_t}'$ <br />\n",
    "$\\mu_{x_t} = H_{x_t}\\mu$ <br />\n",
    "$\\mu_{y_t} = H_{y_t}\\mu$\n",
    "\n",
    "2. $\\hat{\\mu} = \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}H_{y_t}\\big)^{-1} \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}y_t\\big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float32))\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans, k_t):\n",
    "    # for R estimation\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    Z_t_hat = H_yt_trans @ y_t + H_xt_trans @ X_t_hat\n",
    "    \n",
    "    R_hat_sum_part = (Z_t_hat - mu) @ tf.transpose(Z_t_hat - mu) \\\n",
    "                        + H_xt_trans @ (R_xt - R_xtyt @ R_yt_inv @ tf.transpose(R_xtyt)) @ H_xt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k_t*LOG_2PI) \n",
    "    \n",
    "    return R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(mu, R):\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    R_hat_sum = 0\n",
    "    log_p_hat = 0\n",
    "    \n",
    "    for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, y_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans, k_t)\n",
    "        \n",
    "        R_hat_sum += R_hat_sum_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R_hat_sum / n\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)    \n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/137328 [00:00<7:26:40,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:34<00:00, 1455.12it/s]\n",
      "  0%|          | 146/137328 [00:00<01:34, 1454.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.233\n",
      "normalized log_p:     -inf\n",
      "convergence gap:      inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1552.75it/s]\n",
      "  0%|          | 172/137328 [00:00<01:19, 1715.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.935\n",
      "normalized log_p:     -32.233\n",
      "convergence gap:      0.29751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1511.80it/s]\n",
      "  0%|          | 136/137328 [00:00<01:41, 1354.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.784\n",
      "normalized log_p:     -31.935\n",
      "convergence gap:      0.15139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1575.63it/s]\n",
      "  0%|          | 163/137328 [00:00<01:24, 1628.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.688\n",
      "normalized log_p:     -31.784\n",
      "convergence gap:      0.095661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1625.57it/s]\n",
      "  0%|          | 168/137328 [00:00<01:21, 1673.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.621\n",
      "normalized log_p:     -31.688\n",
      "convergence gap:      0.066826\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1654.25it/s]\n",
      "  0%|          | 325/137328 [00:00<01:25, 1606.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.573\n",
      "normalized log_p:     -31.621\n",
      "convergence gap:      0.048315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1571.93it/s]\n",
      "  0%|          | 158/137328 [00:00<01:26, 1578.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.537\n",
      "normalized log_p:     -31.573\n",
      "convergence gap:      0.035978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1572.30it/s]\n",
      "  0%|          | 162/137328 [00:00<01:24, 1618.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.51\n",
      "normalized log_p:     -31.537\n",
      "convergence gap:      0.027323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1498.95it/s]\n",
      "  0%|          | 162/137328 [00:00<01:24, 1617.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.489\n",
      "normalized log_p:     -31.51\n",
      "convergence gap:      0.021065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1631.28it/s]\n",
      "  0%|          | 164/137328 [00:00<01:24, 1632.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.473\n",
      "normalized log_p:     -31.489\n",
      "convergence gap:      0.016228\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1636.63it/s]\n",
      "  0%|          | 165/137328 [00:00<01:23, 1644.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.46\n",
      "normalized log_p:     -31.473\n",
      "convergence gap:      0.012358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1637.46it/s]\n",
      "  0%|          | 325/137328 [00:00<01:24, 1613.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.45\n",
      "normalized log_p:     -31.46\n",
      "convergence gap:      0.0099068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1630.18it/s]\n",
      "  0%|          | 329/137328 [00:00<01:23, 1641.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.443\n",
      "normalized log_p:     -31.45\n",
      "convergence gap:      0.0076714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1632.01it/s]\n",
      "  0%|          | 328/137328 [00:00<01:24, 1630.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.437\n",
      "normalized log_p:     -31.443\n",
      "convergence gap:      0.0059757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1634.29it/s]\n",
      "  0%|          | 326/137328 [00:00<01:24, 1614.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.432\n",
      "normalized log_p:     -31.437\n",
      "convergence gap:      0.0047512\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1637.45it/s]\n",
      "  0%|          | 329/137328 [00:00<01:23, 1635.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.428\n",
      "normalized log_p:     -31.432\n",
      "convergence gap:      0.0035458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1632.88it/s]\n",
      "  0%|          | 164/137328 [00:00<01:24, 1632.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.425\n",
      "normalized log_p:     -31.428\n",
      "convergence gap:      0.0031414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1634.01it/s]\n",
      "  0%|          | 327/137328 [00:00<01:24, 1616.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.423\n",
      "normalized log_p:     -31.425\n",
      "convergence gap:      0.0025272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:34<00:00, 1446.18it/s]\n",
      "  0%|          | 138/137328 [00:00<01:39, 1378.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.421\n",
      "normalized log_p:     -31.423\n",
      "convergence gap:      0.0021458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:38<00:00, 1388.75it/s]\n",
      "  0%|          | 139/137328 [00:00<01:39, 1385.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.419\n",
      "normalized log_p:     -31.421\n",
      "convergence gap:      0.0018673\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:40<00:00, 1363.29it/s]\n",
      "  0%|          | 137/137328 [00:00<01:40, 1362.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.417\n",
      "normalized log_p:     -31.419\n",
      "convergence gap:      0.0013142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:40<00:00, 1361.19it/s]\n",
      "  0%|          | 268/137328 [00:00<01:42, 1332.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.416\n",
      "normalized log_p:     -31.417\n",
      "convergence gap:      0.0011387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:42<00:00, 1344.74it/s]\n",
      "  0%|          | 143/137328 [00:00<01:36, 1423.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.416\n",
      "convergence gap:      0.00089264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:42<00:00, 1343.45it/s]\n",
      "  0%|          | 161/137328 [00:00<01:25, 1599.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.415\n",
      "convergence gap:      0.00057983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1596.86it/s]\n",
      "  0%|          | 156/137328 [00:00<01:28, 1554.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.414\n",
      "normalized log_p:     -31.415\n",
      "convergence gap:      0.00057793\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1517.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.414\n",
      "normalized log_p:     -31.414\n",
      "convergence gap:      0.00049591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float32)\n",
    "\n",
    "for i in range(30):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = expectation_maximization(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print(f'normalized log_p_hat: {(log_p_hat/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'normalized log_p:     {(log_p/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'convergence gap:      {(log_p_hat/n - log_p/n).numpy().flatten()[0]:.5}')\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 iterations, ~38 min\n",
    "np.save('results/em_mu.npy', mu_hat)\n",
    "np.save('results/em_R.npy', R_hat)\n",
    "np.save('results/em_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McMichael’s Algorithm\n",
    "\n",
    "1. $\\hat{R}^{i+1} = \\hat{R}^{i} + \\gamma \\hat{R}^{i} \\bigg(\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} \\bigg) \\hat{R}^{i}$ <br />\n",
    "where $\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} = -\\frac{1}{2} \\sum_{t=1}^{n} H_{y_t}' \\Big(\\big(R_{y_t}^{i}\\big)^{-1} - \\big(R_{y_t}^{i}\\big)^{-1} (y_t - \\mu_{y_t}) (y_t - \\mu_{y_t})' \\big(R_{y_t}^{i}\\big)^{-1}\\Big) H_{y_t}$\n",
    "\n",
    "2. $\\hat{\\mu} = \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}H_{y_t}\\big)^{-1} \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}y_t\\big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans, k_t):\n",
    "    # for R estimation\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k_t*LOG_2PI)\n",
    "    \n",
    "    return log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "\n",
    "    for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, y_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans, k_t)\n",
    "        \n",
    "        log_p_gradient += log_p_gradient_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/137328 [00:00<4:37:27,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:18<00:00, 1747.25it/s]\n",
      "  0%|          | 149/137328 [00:00<01:32, 1488.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.233\n",
      "normalized log_p:     -inf\n",
      "convergence gap:      inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1612.42it/s]\n",
      "  0%|          | 166/137328 [00:00<01:23, 1649.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.007\n",
      "normalized log_p:     -32.233\n",
      "convergence gap:      0.22573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1611.31it/s]\n",
      "  0%|          | 164/137328 [00:00<01:23, 1638.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.874\n",
      "normalized log_p:     -32.007\n",
      "convergence gap:      0.13298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1644.09it/s]\n",
      "  0%|          | 166/137328 [00:00<01:22, 1656.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.783\n",
      "normalized log_p:     -31.874\n",
      "convergence gap:      0.091234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1641.21it/s]\n",
      "  0%|          | 329/137328 [00:00<01:24, 1628.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.715\n",
      "normalized log_p:     -31.783\n",
      "convergence gap:      0.068035\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1692.39it/s]\n",
      "  0%|          | 198/137328 [00:00<01:09, 1969.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.662\n",
      "normalized log_p:     -31.715\n",
      "convergence gap:      0.052494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:10<00:00, 1935.23it/s]\n",
      "  0%|          | 198/137328 [00:00<01:09, 1970.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.62\n",
      "normalized log_p:     -31.662\n",
      "convergence gap:      0.042009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:10<00:00, 1937.09it/s]\n",
      "  0%|          | 198/137328 [00:00<01:09, 1968.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.586\n",
      "normalized log_p:     -31.62\n",
      "convergence gap:      0.033991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:11<00:00, 1924.67it/s]\n",
      "  0%|          | 192/137328 [00:00<01:11, 1916.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.559\n",
      "normalized log_p:     -31.586\n",
      "convergence gap:      0.027643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:13<00:00, 1879.85it/s]\n",
      "  0%|          | 160/137328 [00:00<01:25, 1599.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.536\n",
      "normalized log_p:     -31.559\n",
      "convergence gap:      0.022726\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:18<00:00, 1740.69it/s]\n",
      "  0%|          | 168/137328 [00:00<01:21, 1672.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.517\n",
      "normalized log_p:     -31.536\n",
      "convergence gap:      0.018993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1961.88it/s]\n",
      "  0%|          | 206/137328 [00:00<01:06, 2052.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.501\n",
      "normalized log_p:     -31.517\n",
      "convergence gap:      0.015974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1984.57it/s]\n",
      "  0%|          | 196/137328 [00:00<01:10, 1948.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.488\n",
      "normalized log_p:     -31.501\n",
      "convergence gap:      0.013252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1980.63it/s]\n",
      "  0%|          | 198/137328 [00:00<01:09, 1976.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.477\n",
      "normalized log_p:     -31.488\n",
      "convergence gap:      0.011196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1978.31it/s]\n",
      "  0%|          | 195/137328 [00:00<01:10, 1947.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.467\n",
      "normalized log_p:     -31.477\n",
      "convergence gap:      0.0093307\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1975.03it/s]\n",
      "  0%|          | 200/137328 [00:00<01:08, 1999.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.459\n",
      "normalized log_p:     -31.467\n",
      "convergence gap:      0.0079021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1979.51it/s]\n",
      "  0%|          | 197/137328 [00:00<01:09, 1960.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.452\n",
      "normalized log_p:     -31.459\n",
      "convergence gap:      0.006918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1982.83it/s]\n",
      "  0%|          | 400/137328 [00:00<01:08, 1985.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.447\n",
      "normalized log_p:     -31.452\n",
      "convergence gap:      0.0056458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1981.49it/s]\n",
      "  0%|          | 200/137328 [00:00<01:08, 1991.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.442\n",
      "normalized log_p:     -31.447\n",
      "convergence gap:      0.0048618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1975.39it/s]\n",
      "  0%|          | 400/137328 [00:00<01:08, 1989.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.438\n",
      "normalized log_p:     -31.442\n",
      "convergence gap:      0.0040379\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1972.59it/s]\n",
      "  0%|          | 398/137328 [00:00<01:09, 1976.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.434\n",
      "normalized log_p:     -31.438\n",
      "convergence gap:      0.0034657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1981.25it/s]\n",
      "  0%|          | 403/137328 [00:00<01:08, 1998.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.432\n",
      "normalized log_p:     -31.434\n",
      "convergence gap:      0.0029163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1982.73it/s]\n",
      "  0%|          | 393/137328 [00:00<01:09, 1973.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.429\n",
      "normalized log_p:     -31.432\n",
      "convergence gap:      0.002367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1976.06it/s]\n",
      "  0%|          | 200/137328 [00:00<01:08, 1997.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.427\n",
      "normalized log_p:     -31.429\n",
      "convergence gap:      0.0023689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1977.55it/s]\n",
      "  0%|          | 400/137328 [00:00<01:08, 2003.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.425\n",
      "normalized log_p:     -31.427\n",
      "convergence gap:      0.0019188\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1978.16it/s]\n",
      "  0%|          | 395/137328 [00:00<01:09, 1968.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.423\n",
      "normalized log_p:     -31.425\n",
      "convergence gap:      0.0017338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1981.40it/s]\n",
      "  0%|          | 399/137328 [00:00<01:09, 1964.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.422\n",
      "normalized log_p:     -31.423\n",
      "convergence gap:      0.0015621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1981.76it/s]\n",
      "  0%|          | 197/137328 [00:00<01:09, 1969.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.42\n",
      "normalized log_p:     -31.422\n",
      "convergence gap:      0.0012455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:14<00:00, 1845.72it/s]\n",
      "  0%|          | 147/137328 [00:00<01:33, 1463.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.419\n",
      "normalized log_p:     -31.42\n",
      "convergence gap:      0.0014267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:20<00:00, 1714.52it/s]\n",
      "  0%|          | 197/137328 [00:00<01:09, 1969.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.418\n",
      "normalized log_p:     -31.419\n",
      "convergence gap:      0.00084496\n",
      "iteration: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:11<00:00, 1928.21it/s]\n",
      "  0%|          | 152/137328 [00:00<01:30, 1512.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.417\n",
      "normalized log_p:     -31.418\n",
      "convergence gap:      0.00089836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1684.19it/s]\n",
      "  0%|          | 191/137328 [00:00<01:11, 1909.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.416\n",
      "normalized log_p:     -31.417\n",
      "convergence gap:      0.00074768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1694.34it/s]\n",
      "  0%|          | 162/137328 [00:00<01:24, 1618.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.416\n",
      "normalized log_p:     -31.416\n",
      "convergence gap:      0.00065422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:16<00:00, 1801.93it/s]\n",
      "  0%|          | 310/137328 [00:00<01:25, 1603.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.416\n",
      "convergence gap:      0.00051689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:14<00:00, 1839.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.415\n",
      "convergence gap:      0.0004673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float32)\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print(f'normalized log_p_hat: {(log_p_hat/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'normalized log_p:     {(log_p/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'convergence gap:      {(log_p_hat/n - log_p/n).numpy().flatten()[0]:.5}')\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 iterations, ~38 min\n",
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "$\\epsilon^2 = \\frac{\\sum_{t=1}^{n}\\big(x_t - \\hat{X_t}\\big)'\\big(x_t - \\hat{X_t}\\big)}{\\sum_{t=1}^{n} l_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans):\n",
    "    # calculate X_t_hat\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    \n",
    "    # clip ratings\n",
    "    predictions_t = tf.gather(tf.matmul(H_xt_trans, X_t_hat), indices=movie_ids_t_P_data-1)\n",
    "    predictions_t = tf.clip_by_value(predictions_t, 1, 5)\n",
    "    \n",
    "    return tf.matmul(tf.transpose(ratings_t_P_data - predictions_t), ratings_t_P_data - predictions_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, y_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        square_error += run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans)\n",
    "        l += len(ratings_t_P_data)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1683.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91699296]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_mu = np.load('results/em_mu.npy')\n",
    "em_R = np.load('results/em_R.npy')\n",
    "rmse = evaluate(em_mu, em_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1692.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.917]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
