{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation\n",
    "Reference: https://ieeexplore.ieee.org/document/5430993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = pd.read_csv('data/Y.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "P_data = pd.read_csv('data/P.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       5      2     1\n",
       "1       4      7     1\n",
       "2       4      8     1\n",
       "3       4     11     1\n",
       "4       4     12     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       3      6     1\n",
       "1       5     96     1\n",
       "2       3      1     2\n",
       "3       3     33     3\n",
       "4       5     42     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((3399874, 3), (189699, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())\n",
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100 137328\n",
      "5 100 137328\n"
     ]
    }
   ],
   "source": [
    "print(Y_data['Rating'].unique().max(), Y_data['Movie'].unique().max(), Y_data['User'].unique().max())\n",
    "print(P_data['Rating'].unique().max(), P_data['Movie'].unique().max(), P_data['User'].unique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 137328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = Y_data['Movie'].unique().max(), Y_data['User'].unique().max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices_pair_list(data):\n",
    "    user_id = 1\n",
    "    indices_list = list()\n",
    "    for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        if row['User'] != user_id:\n",
    "            user_id = row['User']\n",
    "            indices_list.append(index - 1)\n",
    "\n",
    "    indices_pair_list = list()\n",
    "    for index_ending in indices_list:\n",
    "        if index_ending == indices_list[0]:\n",
    "            indices_pair_list.append((0, index_ending))\n",
    "        else:\n",
    "            index_beginning = indices_pair_list[-1][1] + 1\n",
    "            indices_pair_list.append((index_beginning, index_ending))\n",
    "    return indices_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3399874/3399874 [03:33<00:00, 15899.35it/s]\n",
      "100%|██████████| 189699/189699 [00:13<00:00, 14002.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_pair_list_Y_data = generate_indices_pair_list(Y_data)\n",
    "indices_pair_list_P_data = generate_indices_pair_list(P_data)\n",
    "len(indices_pair_list_Y_data) == len(indices_pair_list_P_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [02:48<00:00, 815.65it/s] \n"
     ]
    }
   ],
   "source": [
    "data_preprocessed = list()\n",
    "for index_pair_Y_data, index_pair_P_data in tqdm(zip(indices_pair_list_Y_data, indices_pair_list_P_data), total=len(indices_pair_list_Y_data)):\n",
    "    Y_data_t = Y_data.loc[index_pair_Y_data[0]:index_pair_Y_data[1], :]\n",
    "    \n",
    "    movie_ids_t_indices = Y_data_t['Movie'].values - 1    \n",
    "    H_yt = tf.constant(np.identity(k)[movie_ids_t_indices], dtype=tf.float32)\n",
    "    H_xt = tf.constant(np.delete(np.identity(k), movie_ids_t_indices, 0), dtype=tf.float32)    \n",
    "    k_t = tf.constant(H_yt.shape[0], dtype=tf.float32)\n",
    "    \n",
    "    z_t_st_indices = np.vstack((movie_ids_t_indices, np.zeros(movie_ids_t_indices.shape[0], dtype=np.int64))).T\n",
    "    z_t = tf.sparse.to_dense(tf.SparseTensor(indices=z_t_st_indices, values=Y_data_t['Rating'].values.astype(np.float32), dense_shape=[k, 1]))\n",
    "    \n",
    "    y_t = tf.matmul(H_yt, z_t)\n",
    "    x_t = tf.matmul(H_xt, z_t)\n",
    "    \n",
    "    P_data_t = P_data.loc[index_pair_P_data[0]:index_pair_P_data[1], :]\n",
    "    movie_ids_t_P_data = P_data_t['Movie'].values\n",
    "    ratings_t_P_data = tf.expand_dims(P_data_t['Rating'].values.astype(np.float32), axis=1)\n",
    "    data_preprocessed.append((H_yt, H_xt, tf.transpose(H_yt), tf.transpose(H_xt), k_t, z_t, y_t, x_t, movie_ids_t_P_data, ratings_t_P_data))\n",
    "        \n",
    "del Y_data\n",
    "del P_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "$\\mu$ has 1 type available <br />\n",
    "$N = \\sum_{t=1}^{n}H_{y_t}'H_{y_t}$ <br />\n",
    "\n",
    "$\\hat{\\mu}^0 = N^{-1}\\sum_{t-1}^{n}H_{y_t}'y_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [00:10<00:00, 13569.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# initial estimate of mu\n",
    "N = 0\n",
    "H_yty_t = 0\n",
    "    \n",
    "for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, Z_t, y_t, x_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "    N += tf.matmul(H_yt_trans, H_yt)\n",
    "    H_yty_t += tf.matmul(H_yt_trans, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[20017.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0., 23916.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0.,     0., 31634., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [    0.,     0.,     0., ..., 60895.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0., 61520.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0., 64505.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
       "array([[3.4526653, 3.5767686, 3.2878866, 3.9047875, 3.7903547, 3.4441562,\n",
       "        3.190684 , 4.5283504, 3.8201292, 3.6159503, 3.4038272, 3.8372512,\n",
       "        4.076039 , 4.228367 , 3.3539274, 4.0645275, 3.7211962, 3.4870086,\n",
       "        4.1638894, 3.4097998, 3.86926  , 3.435835 , 3.2032225, 4.084879 ,\n",
       "        3.2320046, 3.886682 , 4.331895 , 4.383559 , 4.316363 , 3.8659174,\n",
       "        4.339757 , 3.8914747, 3.7002807, 3.3624778, 4.3289886, 4.0670323,\n",
       "        4.56922  , 3.771041 , 3.6858559, 3.8453238, 4.345388 , 3.9099529,\n",
       "        3.3994992, 3.6078188, 3.9626696, 4.143861 , 3.4072049, 3.7040153,\n",
       "        4.0034695, 4.6428022, 3.216206 , 3.7723858, 4.265651 , 4.4537544,\n",
       "        3.8384895, 3.793742 , 3.76288  , 3.8869822, 3.8004174, 4.346952 ,\n",
       "        3.8046887, 3.8462136, 3.6412156, 3.2722168, 3.4232938, 3.7163155,\n",
       "        3.2069893, 4.4541044, 4.265392 , 3.8610888, 4.483009 , 4.3621464,\n",
       "        3.5388138, 4.1171074, 3.8946686, 3.3607738, 4.179405 , 3.5793724,\n",
       "        3.63975  , 3.9759395, 3.7506986, 3.8211102, 4.034035 , 3.9582725,\n",
       "        3.4913766, 3.4741821, 3.8214757, 3.6429584, 3.4742756, 3.6389303,\n",
       "        3.4526339, 3.504752 , 4.3672986, 4.361775 , 4.0114975, 4.1923757,\n",
       "        3.4806535, 3.8585596, 3.8025846, 3.387365 ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_hat0 = tf.matmul(tf.linalg.inv(N), H_yty_t)\n",
    "tf.transpose(mu_hat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R has 4 types available <br />\n",
    "$R_{1} = I$ <br />\n",
    "\n",
    "$R_{2} = N^{-1}diag(S)$ <br />\n",
    "\n",
    "$R_{3} = diag(S)^{-1/2}Sdiag(S)^{-1/2}$ <br />\n",
    "\n",
    "$R_{4} = N^{-1/2}SN^{-1/2}$ <br />\n",
    "\n",
    "where $S = \\sum_{t=1}^{n}H_{y_{t}}'(y_t - H_{y_{t}}\\hat{\\mu}^0)(y_t - H_{y_{t}}\\hat{\\mu}^0)'H_{y_{t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.eye(k, dtype=tf.float32)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [00:20<00:00, 6749.16it/s]\n"
     ]
    }
   ],
   "source": [
    "S = 0\n",
    "for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, Z_t, y_t, x_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "    Hytmu_hat0 = tf.matmul(H_yt, mu_hat0)\n",
    "    S += H_yt_trans @ (y_t - Hytmu_hat0) @ tf.transpose(y_t - Hytmu_hat0) @ H_yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[1.724364  , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.94218737, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.4365153 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.1832287 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.0349729 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.2620498 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(tf.linalg.inv(N), diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[ 1.        ,  0.07418733, -0.01158332, ..., -0.01462825,\n",
       "        -0.02215315, -0.0184503 ],\n",
       "       [ 0.07418733,  0.99999994,  0.03674516, ...,  0.02561875,\n",
       "         0.03563373,  0.0392758 ],\n",
       "       [-0.01158332,  0.03674517,  0.9999999 , ...,  0.1095439 ,\n",
       "         0.12823555,  0.15562423],\n",
       "       ...,\n",
       "       [-0.01462825,  0.02561875,  0.1095439 , ...,  1.0000001 ,\n",
       "         0.1978014 ,  0.15164192],\n",
       "       [-0.02215315,  0.03563373,  0.12823555, ...,  0.19780138,\n",
       "         1.0000001 ,  0.18996929],\n",
       "       [-0.0184503 ,  0.0392758 ,  0.15562423, ...,  0.15164192,\n",
       "         0.18996929,  1.0000001 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "R_hat0_3 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(diag_S)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(diag_S))))\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[ 1.724364  ,  0.09456117, -0.01823068, ..., -0.02089494,\n",
       "        -0.02959474, -0.02721799],\n",
       "       [ 0.09456117,  0.94218737,  0.04274881, ...,  0.0270496 ,\n",
       "         0.03518798,  0.04282841],\n",
       "       [-0.01823068,  0.04274881,  1.4365153 , ...,  0.14281628,\n",
       "         0.15636086,  0.20954175],\n",
       "       ...,\n",
       "       [-0.02089494,  0.0270496 ,  0.14281628, ...,  1.1832289 ,\n",
       "         0.21889113,  0.18530701],\n",
       "       [-0.02959474,  0.03518798,  0.15636086, ...,  0.21889113,\n",
       "         1.0349729 ,  0.21711312],\n",
       "       [-0.02721799,  0.0428284 ,  0.20954177, ...,  0.18530701,\n",
       "         0.21711312,  1.2620498 ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat0_4 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(N)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(N))))\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\mu} = \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}H_{y_t}\\big)^{-1} \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}y_t\\big)$\n",
    "\n",
    "$\\hat{R}^{i+1} = \\frac{1}{n} \\sum_{t=1}^{n} (\\hat{Z}_t - \\mu)(\\hat{Z}_t - \\mu)' + H_{x_t}' \\bigg(\\hat{R}_{x_t}^{i} - \\hat{R}_{x_ty_t}^{i} \\big(\\hat{R}_{y_t}^{i}\\big)^{-1} \\big(\\hat{R}_{x_ty_t}^{i}\\big)'\\bigg) H_{x_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float32))\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans, k_t):\n",
    "    # for R estimation\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    Z_t_hat = H_yt_trans @ y_t + H_xt_trans @ X_t_hat\n",
    "    \n",
    "    R_hat_sum_part = (Z_t_hat - mu) @ tf.transpose(Z_t_hat - mu) \\\n",
    "                        + H_xt_trans @ (R_xt - R_xtyt @ R_yt_inv @ tf.transpose(R_xtyt)) @ H_xt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k_t*LOG_2PI) \n",
    "    \n",
    "    return R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(mu, R):\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    R_hat_sum = 0\n",
    "    log_p_hat = 0\n",
    "    \n",
    "    for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, Z_t, y_t, x_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans, k_t)\n",
    "        \n",
    "        R_hat_sum += R_hat_sum_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R_hat_sum / n\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)    \n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:43<00:00, 1326.56it/s]\n",
      "  0%|          | 169/137327 [00:00<01:21, 1684.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.232\n",
      "normalized log_p:     -inf\n",
      "convergence gap:      inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1564.28it/s]\n",
      "  0%|          | 126/137327 [00:00<01:48, 1259.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.935\n",
      "normalized log_p:     -32.232\n",
      "convergence gap:      0.29751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:47<00:00, 1273.50it/s]\n",
      "  0%|          | 125/137327 [00:00<01:49, 1248.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.784\n",
      "normalized log_p:     -31.935\n",
      "convergence gap:      0.15139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:34<00:00, 1453.54it/s]\n",
      "  0%|          | 171/137327 [00:00<01:20, 1705.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.688\n",
      "normalized log_p:     -31.784\n",
      "convergence gap:      0.095654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:42<00:00, 1340.25it/s]\n",
      "  0%|          | 142/137327 [00:00<01:36, 1416.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.621\n",
      "normalized log_p:     -31.688\n",
      "convergence gap:      0.066853\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:41<00:00, 1350.48it/s]\n",
      "  0%|          | 140/137327 [00:00<01:38, 1395.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.573\n",
      "normalized log_p:     -31.621\n",
      "convergence gap:      0.048288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:39<00:00, 1374.15it/s]\n",
      "  0%|          | 235/137327 [00:00<01:57, 1168.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.537\n",
      "normalized log_p:     -31.573\n",
      "convergence gap:      0.035984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1283.49it/s]\n",
      "  0%|          | 130/137327 [00:00<01:45, 1295.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.509\n",
      "normalized log_p:     -31.537\n",
      "convergence gap:      0.027332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1291.84it/s]\n",
      "  0%|          | 244/137327 [00:00<01:53, 1209.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.488\n",
      "normalized log_p:     -31.509\n",
      "convergence gap:      0.021059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1283.78it/s]\n",
      "  0%|          | 256/137327 [00:00<01:47, 1274.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.472\n",
      "normalized log_p:     -31.488\n",
      "convergence gap:      0.016197\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1289.86it/s]\n",
      "  0%|          | 264/137327 [00:00<01:44, 1314.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.46\n",
      "normalized log_p:     -31.472\n",
      "convergence gap:      0.012394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1285.26it/s]\n",
      "  0%|          | 140/137327 [00:00<01:38, 1393.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.45\n",
      "normalized log_p:     -31.46\n",
      "convergence gap:      0.0099144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:44<00:00, 1311.87it/s]\n",
      "  0%|          | 135/137327 [00:00<01:41, 1349.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.442\n",
      "normalized log_p:     -31.45\n",
      "convergence gap:      0.0076313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:45<00:00, 1298.14it/s]\n",
      "  0%|          | 284/137327 [00:00<01:37, 1403.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.436\n",
      "normalized log_p:     -31.442\n",
      "convergence gap:      0.0059929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:44<00:00, 1309.76it/s]\n",
      "  0%|          | 141/137327 [00:00<01:37, 1409.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.432\n",
      "normalized log_p:     -31.436\n",
      "convergence gap:      0.0047302\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1286.99it/s]\n",
      "  0%|          | 130/137327 [00:00<01:45, 1298.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.428\n",
      "normalized log_p:     -31.432\n",
      "convergence gap:      0.003582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:46<00:00, 1288.67it/s]\n",
      "  0%|          | 153/137327 [00:00<01:29, 1526.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.425\n",
      "normalized log_p:     -31.428\n",
      "convergence gap:      0.0031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1568.93it/s]\n",
      "  0%|          | 161/137327 [00:00<01:25, 1608.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.422\n",
      "normalized log_p:     -31.425\n",
      "convergence gap:      0.0025425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:26<00:00, 1582.39it/s]\n",
      "  0%|          | 144/137327 [00:00<01:35, 1438.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.42\n",
      "normalized log_p:     -31.422\n",
      "convergence gap:      0.0021477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1577.47it/s]\n",
      "  0%|          | 164/137327 [00:00<01:23, 1633.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.418\n",
      "normalized log_p:     -31.42\n",
      "convergence gap:      0.0018711\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1578.26it/s]\n",
      "  0%|          | 149/137327 [00:00<01:32, 1482.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.417\n",
      "normalized log_p:     -31.418\n",
      "convergence gap:      0.001297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:26<00:00, 1580.97it/s]\n",
      "  0%|          | 325/137327 [00:00<01:25, 1611.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.416\n",
      "normalized log_p:     -31.417\n",
      "convergence gap:      0.0011024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1577.81it/s]\n",
      "  0%|          | 308/137327 [00:00<01:30, 1517.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.416\n",
      "convergence gap:      0.00092125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:26<00:00, 1581.65it/s]\n",
      "  0%|          | 161/137327 [00:00<01:25, 1604.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.414\n",
      "normalized log_p:     -31.415\n",
      "convergence gap:      0.00056458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1575.98it/s]\n",
      "  0%|          | 165/137327 [00:00<01:23, 1647.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.414\n",
      "normalized log_p:     -31.414\n",
      "convergence gap:      0.00056076\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1577.46it/s]\n",
      "  0%|          | 138/137327 [00:00<01:39, 1372.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.413\n",
      "normalized log_p:     -31.414\n",
      "convergence gap:      0.00052834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1575.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.413\n",
      "normalized log_p:     -31.413\n",
      "convergence gap:      0.00042915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float32)\n",
    "\n",
    "for i in range(30):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = expectation_maximization(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print(f'normalized log_p_hat: {(log_p_hat/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'normalized log_p:     {(log_p/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'convergence gap:      {(log_p_hat/n - log_p/n).numpy().flatten()[0]:.5}')\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 iterations, ~38 min\n",
    "np.save('results/em_mu.npy', mu_hat)\n",
    "np.save('results/em_R.npy', R_hat)\n",
    "np.save('results/em_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McMichael’s Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\mu} = \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}H_{y_t}\\big)^{-1} \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}y_t\\big)$\n",
    "\n",
    "$\\hat{R}^{i+1} = \\hat{R}^{i} + \\gamma \\hat{R}^{i} \\bigg(\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} \\bigg) \\hat{R}^{i}$\n",
    "\n",
    "where $\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} = -\\frac{1}{2} \\sum_{t=1}^{n} H_{y_t}' \\Big(\\big(R_{y_t}^{i}\\big)^{-1} - \\big(R_{y_t}^{i}\\big)^{-1} (y_t - \\mu_{y_t}) (y_t - \\mu_{y_t})' \\big(R_{y_t}^{i}\\big)^{-1}\\Big) H_{y_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans, k_t):\n",
    "    # for R estimation\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k_t*LOG_2PI)\n",
    "    \n",
    "    return log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "\n",
    "    for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, Z_t, y_t, x_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans, k_t)\n",
    "        \n",
    "        log_p_gradient += log_p_gradient_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/137327 [00:00<5:44:25,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:15<00:00, 1818.08it/s]\n",
      "  0%|          | 366/137327 [00:00<01:19, 1729.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.232\n",
      "normalized log_p:     -inf\n",
      "convergence gap:      inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:12<00:00, 1881.44it/s]\n",
      "  0%|          | 198/137327 [00:00<01:09, 1974.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.007\n",
      "normalized log_p:     -32.232\n",
      "convergence gap:      0.22573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:11<00:00, 1923.70it/s]\n",
      "  0%|          | 196/137327 [00:00<01:10, 1956.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.874\n",
      "normalized log_p:     -32.007\n",
      "convergence gap:      0.13298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1970.84it/s]\n",
      "  0%|          | 192/137327 [00:00<01:11, 1912.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.783\n",
      "normalized log_p:     -31.874\n",
      "convergence gap:      0.091223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1971.59it/s]\n",
      "  0%|          | 195/137327 [00:00<01:10, 1947.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.714\n",
      "normalized log_p:     -31.783\n",
      "convergence gap:      0.068048\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1971.31it/s]\n",
      "  0%|          | 197/137327 [00:00<01:09, 1969.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.662\n",
      "normalized log_p:     -31.714\n",
      "convergence gap:      0.052481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1976.41it/s]\n",
      "  0%|          | 198/137327 [00:00<01:09, 1977.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.62\n",
      "normalized log_p:     -31.662\n",
      "convergence gap:      0.042002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1981.92it/s]\n",
      "  0%|          | 198/137327 [00:00<01:09, 1974.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.586\n",
      "normalized log_p:     -31.62\n",
      "convergence gap:      0.033998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1979.69it/s]\n",
      "  0%|          | 398/137327 [00:00<01:09, 1973.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.558\n",
      "normalized log_p:     -31.586\n",
      "convergence gap:      0.027645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1982.43it/s]\n",
      "  0%|          | 200/137327 [00:00<01:08, 1994.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.536\n",
      "normalized log_p:     -31.558\n",
      "convergence gap:      0.022732\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1979.73it/s]\n",
      "  0%|          | 395/137327 [00:00<01:09, 1959.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.517\n",
      "normalized log_p:     -31.536\n",
      "convergence gap:      0.018993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1974.57it/s]\n",
      "  0%|          | 395/137327 [00:00<01:09, 1970.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.501\n",
      "normalized log_p:     -31.517\n",
      "convergence gap:      0.015959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1978.34it/s]\n",
      "  0%|          | 395/137327 [00:00<01:09, 1962.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.487\n",
      "normalized log_p:     -31.501\n",
      "convergence gap:      0.013268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1981.38it/s]\n",
      "  0%|          | 200/137327 [00:00<01:08, 1995.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.476\n",
      "normalized log_p:     -31.487\n",
      "convergence gap:      0.011173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1980.86it/s]\n",
      "  0%|          | 404/137327 [00:00<01:08, 2011.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.467\n",
      "normalized log_p:     -31.476\n",
      "convergence gap:      0.009346\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1977.55it/s]\n",
      "  0%|          | 200/137327 [00:00<01:08, 1998.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.459\n",
      "normalized log_p:     -31.467\n",
      "convergence gap:      0.0079193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1982.33it/s]\n",
      "  0%|          | 198/137327 [00:00<01:09, 1976.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.452\n",
      "normalized log_p:     -31.459\n",
      "convergence gap:      0.0069141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1974.76it/s]\n",
      "  0%|          | 200/137327 [00:00<01:08, 1991.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.446\n",
      "normalized log_p:     -31.452\n",
      "convergence gap:      0.0056477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1979.07it/s]\n",
      "  0%|          | 401/137327 [00:00<01:08, 2000.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.442\n",
      "normalized log_p:     -31.446\n",
      "convergence gap:      0.0048523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1978.41it/s]\n",
      "  0%|          | 198/137327 [00:00<01:09, 1970.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.438\n",
      "normalized log_p:     -31.442\n",
      "convergence gap:      0.0040321\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:10<00:00, 1960.52it/s]\n",
      "  0%|          | 402/137327 [00:00<01:08, 1994.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.434\n",
      "normalized log_p:     -31.438\n",
      "convergence gap:      0.0034504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1995.75it/s]\n",
      "  0%|          | 201/137327 [00:00<01:08, 2008.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.431\n",
      "normalized log_p:     -31.434\n",
      "convergence gap:      0.0029392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1998.54it/s]\n",
      "  0%|          | 398/137327 [00:00<01:09, 1969.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.429\n",
      "normalized log_p:     -31.431\n",
      "convergence gap:      0.0023556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1995.15it/s]\n",
      "  0%|          | 201/137327 [00:00<01:08, 2007.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.426\n",
      "normalized log_p:     -31.429\n",
      "convergence gap:      0.0023518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1993.56it/s]\n",
      "  0%|          | 401/137327 [00:00<01:08, 1999.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.424\n",
      "normalized log_p:     -31.426\n",
      "convergence gap:      0.0019512\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1993.10it/s]\n",
      "  0%|          | 200/137327 [00:00<01:08, 1993.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.423\n",
      "normalized log_p:     -31.424\n",
      "convergence gap:      0.00173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 2001.29it/s]\n",
      "  0%|          | 202/137327 [00:00<01:08, 2015.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.421\n",
      "normalized log_p:     -31.423\n",
      "convergence gap:      0.0015507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1997.97it/s]\n",
      "  0%|          | 412/137327 [00:00<01:07, 2035.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.42\n",
      "normalized log_p:     -31.421\n",
      "convergence gap:      0.0012455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1997.75it/s]\n",
      "  0%|          | 404/137327 [00:00<01:07, 2014.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.419\n",
      "normalized log_p:     -31.42\n",
      "convergence gap:      0.0014305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1999.82it/s]\n",
      "  0%|          | 404/137327 [00:00<01:08, 2000.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.418\n",
      "normalized log_p:     -31.419\n",
      "convergence gap:      0.00083733\n",
      "iteration: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1984.02it/s]\n",
      "  0%|          | 201/137327 [00:00<01:08, 2005.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.417\n",
      "normalized log_p:     -31.418\n",
      "convergence gap:      0.00090981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:09<00:00, 1982.27it/s]\n",
      "  0%|          | 202/137327 [00:00<01:08, 2012.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.416\n",
      "normalized log_p:     -31.417\n",
      "convergence gap:      0.0007534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 2000.72it/s]\n",
      "  0%|          | 400/137327 [00:00<01:08, 1988.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.416\n",
      "convergence gap:      0.00063515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1997.27it/s]\n",
      "  0%|          | 402/137327 [00:00<01:07, 2015.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.415\n",
      "normalized log_p:     -31.415\n",
      "convergence gap:      0.00051689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:08<00:00, 1999.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -31.414\n",
      "normalized log_p:     -31.415\n",
      "convergence gap:      0.00044441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float32)\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print(f'normalized log_p_hat: {(log_p_hat/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'normalized log_p:     {(log_p/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'convergence gap:      {(log_p_hat/n - log_p/n).numpy().flatten()[0]:.5}')\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 iterations, ~38 min\n",
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans):\n",
    "    # calculate X_t_hat\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    \n",
    "    # clip ratings\n",
    "    predictions_t = tf.gather(tf.matmul(H_xt_trans, X_t_hat), indices=movie_ids_t_P_data-1)\n",
    "    predictions_t = tf.clip_by_value(predictions_t, 1, 5)\n",
    "    \n",
    "    return tf.matmul(tf.transpose(ratings_t_P_data - predictions_t), ratings_t_P_data - predictions_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for (H_yt, H_xt, H_yt_trans, H_xt_trans, k_t, Z_t, y_t, x_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        square_error += run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans)\n",
    "        l += len(ratings_t_P_data)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:16<00:00, 1806.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9169972]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_mu = np.load('results/em_mu.npy')\n",
    "em_R = np.load('results/em_R.npy')\n",
    "rmse = evaluate(em_mu, em_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:14<00:00, 1837.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91700095]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
