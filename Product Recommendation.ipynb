{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation\n",
    "Reference: https://ieeexplore.ieee.org/document/5430993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = pd.read_csv('data/Y.csv', header=None, names=['Rating','Movie','User'], dtype=int) # training data\n",
    "P_data = pd.read_csv('data/P.csv', header=None, names=['Rating','Movie','User'], dtype=int) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       5      2     1\n",
       "1       4      7     1\n",
       "2       4      8     1\n",
       "3       4     11     1\n",
       "4       4     12     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       3      6     1\n",
       "1       5     96     1\n",
       "2       3      1     2\n",
       "3       3     33     3\n",
       "4       5     42     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3399874, 3), (189699, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100 137328\n",
      "5 100 137328\n"
     ]
    }
   ],
   "source": [
    "print(Y_data['Rating'].unique().max(), Y_data['Movie'].unique().max(), Y_data['User'].unique().max())\n",
    "print(P_data['Rating'].unique().max(), P_data['Movie'].unique().max(), P_data['User'].unique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 137328)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = Y_data['Movie'].unique().max(), Y_data['User'].unique().max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3399874, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[     1,      0],\n",
       "       [     6,      0],\n",
       "       [     7,      0],\n",
       "       ...,\n",
       "       [    97, 137327],\n",
       "       [    98, 137327],\n",
       "       [    99, 137327]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.reshape(Y_data[['Movie', 'User']].values-1, (-1, 2))\n",
    "print(indices.shape)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_sparse = tf.SparseTensor(indices=indices, values=Y_data['Rating'].values, dense_shape=[k, n])\n",
    "Z_sparse = tf.cast(Z_sparse, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# t = 0\n",
    "# Z_t = tf.sparse.slice(Z_sparse, [0, t], [100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 137328), dtype=float64, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 3.],\n",
       "       [0., 0., 0., ..., 3., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 4., 0., 4.],\n",
       "       [4., 0., 3., ..., 0., 0., 4.],\n",
       "       [3., 4., 0., ..., 4., 5., 4.]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dense matrices for faster linear transformations since all matrices can fit in memory\n",
    "Z = tf.sparse.to_dense(Z_sparse, validate_indices=False)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [13:13<00:00, 173.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# memoization\n",
    "t_Z_dict = {}\n",
    "t_y_dict = {}\n",
    "t_x_dict = {}\n",
    "t_Hy_dict = {}\n",
    "t_Hx_dict = {}\n",
    "t_Hy_trans_dict = {}\n",
    "t_Hx_trans_dict = {}\n",
    "t_movie_ids_labels_dict = {}\n",
    "t_labels_dict = {}\n",
    "\n",
    "for t in tqdm(range(n)):\n",
    "    movie_ids = Y_data['Movie'][Y_data['User']==t+1].values\n",
    "    H_yt = tf.constant(np.identity(k)[movie_ids-1], dtype=tf.float64)\n",
    "    H_xt = tf.constant(np.delete(np.identity(k), movie_ids-1, 0), dtype=tf.float64)\n",
    "    Z_t = tf.expand_dims(Z[:, t], axis=1) # alternative: Z_t = tf.sparse.slice(Z_sparse, [0, t], [100, 1]) \n",
    "    y_t = tf.matmul(H_yt, Z_t)\n",
    "    x_t = tf.matmul(H_xt, Z_t)\n",
    "    \n",
    "    # store the variables for fast future reference\n",
    "    t_Hy_dict[t] = H_yt\n",
    "    t_Hx_dict[t] = H_xt\n",
    "    t_Hx_trans_dict[t] = tf.transpose(H_xt)\n",
    "    t_Hy_trans_dict[t] = tf.transpose(H_yt)\n",
    "    \n",
    "    t_x_dict[t] = x_t\n",
    "    t_y_dict[t] = y_t\n",
    "    t_Z_dict[t] = Z_t\n",
    "    \n",
    "    t_movie_ids_labels_dict[t] = P_data['Movie'][P_data['User']==t+1].values\n",
    "    t_labels_dict[t] = tf.expand_dims(P_data['Rating'][P_data['User']==t+1].values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "$\\mu$ has 1 type available <br />\n",
    "R has 4 types available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:15<00:00, 9045.02it/s] \n"
     ]
    }
   ],
   "source": [
    "# initial estimate of mu\n",
    "N = 0\n",
    "H_yty_t = 0\n",
    "\n",
    "for t in tqdm(range(n)):\n",
    "    N += tf.matmul(t_Hy_trans_dict[t], t_Hy_dict[t])\n",
    "    H_yty_t += tf.matmul(t_Hy_trans_dict[t], t_y_dict[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[20017.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0., 23917.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0.,     0., 31634., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [    0.,     0.,     0., ..., 60896.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0., 61521.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0., 64506.]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(H_yty_t.shape)\n",
    "mu_hat0 = tf.matmul(tf.linalg.inv(N), H_yty_t)\n",
    "mu_hat0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.constant(np.identity(k), dtype=tf.float64)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:31<00:00, 4342.29it/s]\n"
     ]
    }
   ],
   "source": [
    "S = 0\n",
    "for t in tqdm(range(n)):\n",
    "    Hyt = t_Hy_dict[t]\n",
    "    yt = t_y_dict[t]\n",
    "    Hytmu_hat0 = tf.matmul(Hyt, mu_hat0)\n",
    "    S += tf.matmul(tf.transpose(Hyt), tf.matmul(yt - Hytmu_hat0, tf.matmul(tf.transpose(yt - Hytmu_hat0), Hyt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[1.72440427, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.94219113, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.43659411, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.18291506, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.03485685,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.26227449]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(tf.linalg.inv(N), diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[ 1.        ,  0.07418256, -0.01158277, ..., -0.01462987,\n",
       "        -0.02215371, -0.01844816],\n",
       "       [ 0.07418256,  1.        ,  0.03674347, ...,  0.0256191 ,\n",
       "         0.03563234,  0.03926307],\n",
       "       [-0.01158277,  0.03674347,  1.        , ...,  0.10955311,\n",
       "         0.12823359,  0.15560634],\n",
       "       ...,\n",
       "       [-0.01462987,  0.0256191 ,  0.10955311, ...,  1.        ,\n",
       "         0.19781317,  0.15164928],\n",
       "       [-0.02215371,  0.03563234,  0.12823359, ...,  0.19781317,\n",
       "         1.        ,  0.18995689],\n",
       "       [-0.01844816,  0.03926307,  0.15560634, ...,  0.15164928,\n",
       "         0.18995689,  1.        ]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "R_hat0_3 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(diag_S)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(diag_S))))\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[ 1.72440427,  0.09455639, -0.01823052, ..., -0.02089473,\n",
       "        -0.02959417, -0.02721758],\n",
       "       [ 0.09455639,  0.94219113,  0.04274809, ...,  0.02704644,\n",
       "         0.03518471,  0.04281842],\n",
       "       [-0.01823052,  0.04274809,  1.43659411, ...,  0.14281326,\n",
       "         0.15635399,  0.20954206],\n",
       "       ...,\n",
       "       [-0.02089473,  0.02704644,  0.14281326, ...,  1.18291506,\n",
       "         0.21886288,  0.18530794],\n",
       "       [-0.02959417,  0.03518471,  0.15635399, ...,  0.21886288,\n",
       "         1.03485685,  0.21710614],\n",
       "       [-0.02721758,  0.04281842,  0.20954206, ...,  0.18530794,\n",
       "         0.21710614,  1.26227449]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat0_4 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(N)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(N))))\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float64))\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans):\n",
    "    # for R estimation\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    Z_t_hat = H_yt_trans @ y_t + H_xt_trans @ X_t_hat\n",
    "    \n",
    "    R_hat_sum_part = (Z_t_hat - mu) @ tf.transpose(Z_t_hat - mu) \\\n",
    "                        + H_xt_trans @ (R_xt - R_xtyt @ R_yt_inv @ tf.transpose(R_xtyt)) @ H_xt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "\n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k*LOG_2PI) \n",
    "    \n",
    "    return R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(mu, R):\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    R_hat_sum = 0\n",
    "    log_p_hat = 0\n",
    "    \n",
    "    for t in tqdm(range(n)):\n",
    "        y_t = t_y_dict[t]\n",
    "        H_xt = t_Hx_dict[t]\n",
    "        H_xt_trans = t_Hx_trans_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans)\n",
    "        \n",
    "        R_hat_sum += R_hat_sum_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R_hat_sum / n\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)    \n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/137328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:42<00:00, 1344.10it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1587.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.37606558]]\n",
      "normalized log_p: -inf\n",
      "convergence gap: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1561.18it/s]\n",
      "  0%|          | 168/137328 [00:00<01:21, 1677.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.07910104]]\n",
      "normalized log_p: [[-101.37606558]]\n",
      "convergence gap: [[0.29696454]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1603.79it/s]\n",
      "  0%|          | 170/137328 [00:00<01:20, 1694.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.92736468]]\n",
      "normalized log_p: [[-101.07910104]]\n",
      "convergence gap: [[0.15173636]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1632.86it/s]\n",
      "  0%|          | 162/137328 [00:00<01:24, 1617.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.83160767]]\n",
      "normalized log_p: [[-100.92736468]]\n",
      "convergence gap: [[0.09575701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:22<00:00, 1662.50it/s]\n",
      "  0%|          | 161/137328 [00:00<01:25, 1602.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.76501937]]\n",
      "normalized log_p: [[-100.83160767]]\n",
      "convergence gap: [[0.0665883]]\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1566.43it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1583.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.71663616]]\n",
      "normalized log_p: [[-100.76501937]]\n",
      "convergence gap: [[0.04838321]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1586.35it/s]\n",
      "  0%|          | 160/137328 [00:00<01:25, 1595.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.68061666]]\n",
      "normalized log_p: [[-100.71663616]]\n",
      "convergence gap: [[0.03601951]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1552.16it/s]\n",
      "  0%|          | 157/137328 [00:00<01:27, 1569.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.65335758]]\n",
      "normalized log_p: [[-100.68061666]]\n",
      "convergence gap: [[0.02725908]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:32<00:00, 1478.74it/s]\n",
      "  0%|          | 322/137328 [00:00<01:25, 1600.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.63248001]]\n",
      "normalized log_p: [[-100.65335758]]\n",
      "convergence gap: [[0.02087757]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:34<00:00, 1460.13it/s]\n",
      "  0%|          | 138/137328 [00:00<01:39, 1373.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.61634676]]\n",
      "normalized log_p: [[-100.63248001]]\n",
      "convergence gap: [[0.01613325]]\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1555.92it/s]\n",
      "  0%|          | 173/137328 [00:00<01:19, 1729.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.60379461]]\n",
      "normalized log_p: [[-100.61634676]]\n",
      "convergence gap: [[0.01255214]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1675.64it/s]\n",
      "  0%|          | 161/137328 [00:00<01:25, 1607.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.59397571]]\n",
      "normalized log_p: [[-100.60379461]]\n",
      "convergence gap: [[0.0098189]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1687.36it/s]\n",
      "  0%|          | 171/137328 [00:00<01:20, 1700.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5862597]]\n",
      "normalized log_p: [[-100.59397571]]\n",
      "convergence gap: [[0.00771601]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1677.54it/s]\n",
      "  0%|          | 167/137328 [00:00<01:22, 1665.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.58017111]]\n",
      "normalized log_p: [[-100.5862597]]\n",
      "convergence gap: [[0.00608859]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1677.41it/s]\n",
      "  0%|          | 171/137328 [00:00<01:20, 1701.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5753476]]\n",
      "normalized log_p: [[-100.58017111]]\n",
      "convergence gap: [[0.0048235]]\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1687.23it/s]\n",
      "  0%|          | 327/137328 [00:00<01:26, 1575.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57151119]]\n",
      "normalized log_p: [[-100.5753476]]\n",
      "convergence gap: [[0.00383642]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:21<00:00, 1676.57it/s]\n",
      "  0%|          | 167/137328 [00:00<01:22, 1663.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56844755]]\n",
      "normalized log_p: [[-100.57151119]]\n",
      "convergence gap: [[0.00306364]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1585.54it/s]\n",
      "  0%|          | 169/137328 [00:00<01:21, 1685.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56599094]]\n",
      "normalized log_p: [[-100.56844755]]\n",
      "convergence gap: [[0.00245661]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1635.94it/s]\n",
      "  0%|          | 167/137328 [00:00<01:22, 1669.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56401278]]\n",
      "normalized log_p: [[-100.56599094]]\n",
      "convergence gap: [[0.00197815]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1616.06it/s]\n",
      "  0%|          | 166/137328 [00:00<01:22, 1653.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56241312]]\n",
      "normalized log_p: [[-100.56401278]]\n",
      "convergence gap: [[0.00159966]]\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1596.70it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1587.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.561114]]\n",
      "normalized log_p: [[-100.56241312]]\n",
      "convergence gap: [[0.00129912]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1593.45it/s]\n",
      "  0%|          | 157/137328 [00:00<01:27, 1560.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56005448]]\n",
      "normalized log_p: [[-100.561114]]\n",
      "convergence gap: [[0.00105952]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1614.18it/s]\n",
      "  0%|          | 162/137328 [00:00<01:24, 1613.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55918673]]\n",
      "normalized log_p: [[-100.56005448]]\n",
      "convergence gap: [[0.00086775]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1610.18it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1587.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55847312]]\n",
      "normalized log_p: [[-100.55918673]]\n",
      "convergence gap: [[0.00071361]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:25<00:00, 1602.35it/s]\n",
      "  0%|          | 161/137328 [00:00<01:25, 1602.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55788391]]\n",
      "normalized log_p: [[-100.55847312]]\n",
      "convergence gap: [[0.00058921]]\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:24<00:00, 1616.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5573955]]\n",
      "normalized log_p: [[-100.55788391]]\n",
      "convergence gap: [[0.00048841]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float64)\n",
    "\n",
    "for i in range(30):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = expectation_maximization(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print('normalized log_p_hat:', (log_p_hat/n).numpy())\n",
    "    print('normalized log_p:', (log_p/n).numpy())\n",
    "    print('convergence gap:', (log_p_hat/n - log_p/n).numpy())\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 iterations, ~39 min\n",
    "np.save('results/em_mu.npy', mu_hat)\n",
    "np.save('results/em_R.npy', R_hat)\n",
    "np.save('results/em_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McMichael’s Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans):\n",
    "    # for R estimation\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k*LOG_2PI)\n",
    "    \n",
    "    return log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "\n",
    "    for t in tqdm(range(n)):\n",
    "        y_t = t_y_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans)\n",
    "        \n",
    "        log_p_gradient += log_p_gradient_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/137328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2262.36it/s]\n",
      "  0%|          | 203/137328 [00:00<01:07, 2021.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.37606558]]\n",
      "normalized log_p: -inf\n",
      "convergence gap: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2297.82it/s]\n",
      "  0%|          | 209/137328 [00:00<01:05, 2082.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.15033828]]\n",
      "normalized log_p: [[-101.37606558]]\n",
      "convergence gap: [[0.2257273]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2216.47it/s]\n",
      "  0%|          | 216/137328 [00:00<01:03, 2151.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.0176644]]\n",
      "normalized log_p: [[-101.15033828]]\n",
      "convergence gap: [[0.13267387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2218.82it/s]\n",
      "  0%|          | 479/137328 [00:00<00:57, 2366.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.92620553]]\n",
      "normalized log_p: [[-101.0176644]]\n",
      "convergence gap: [[0.09145888]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2215.60it/s]\n",
      "  0%|          | 432/137328 [00:00<01:03, 2146.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.85833264]]\n",
      "normalized log_p: [[-100.92620553]]\n",
      "convergence gap: [[0.06787289]]\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2205.16it/s]\n",
      "  0%|          | 234/137328 [00:00<00:59, 2322.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.80569404]]\n",
      "normalized log_p: [[-100.85833264]]\n",
      "convergence gap: [[0.0526386]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2236.29it/s]\n",
      "  0%|          | 444/137328 [00:00<01:03, 2165.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.76380998]]\n",
      "normalized log_p: [[-100.80569404]]\n",
      "convergence gap: [[0.04188405]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2202.84it/s]\n",
      "  0%|          | 236/137328 [00:00<00:58, 2355.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.72994344]]\n",
      "normalized log_p: [[-100.76380998]]\n",
      "convergence gap: [[0.03386655]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2211.46it/s]\n",
      "  0%|          | 235/137328 [00:00<00:58, 2343.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.7022525]]\n",
      "normalized log_p: [[-100.72994344]]\n",
      "convergence gap: [[0.02769093]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2213.90it/s]\n",
      "  0%|          | 478/137328 [00:00<00:57, 2368.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.67941999]]\n",
      "normalized log_p: [[-100.7022525]]\n",
      "convergence gap: [[0.02283252]]\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2175.11it/s]\n",
      "  0%|          | 434/137328 [00:00<01:03, 2151.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.66046803]]\n",
      "normalized log_p: [[-100.67941999]]\n",
      "convergence gap: [[0.01895195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2225.26it/s]\n",
      "  0%|          | 216/137328 [00:00<01:03, 2150.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.64465236]]\n",
      "normalized log_p: [[-100.66046803]]\n",
      "convergence gap: [[0.01581567]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2234.19it/s]\n",
      "  0%|          | 235/137328 [00:00<00:58, 2347.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.63139579]]\n",
      "normalized log_p: [[-100.64465236]]\n",
      "convergence gap: [[0.01325658]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2217.37it/s]\n",
      "  0%|          | 218/137328 [00:00<01:03, 2172.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.62024378]]\n",
      "normalized log_p: [[-100.63139579]]\n",
      "convergence gap: [[0.01115201]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2239.62it/s]\n",
      "  0%|          | 212/137328 [00:00<01:04, 2114.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.6108337]]\n",
      "normalized log_p: [[-100.62024378]]\n",
      "convergence gap: [[0.00941008]]\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2393.63it/s]\n",
      "  0%|          | 496/137328 [00:00<00:55, 2463.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.60287292]]\n",
      "normalized log_p: [[-100.6108337]]\n",
      "convergence gap: [[0.00796078]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2339.16it/s]\n",
      "  0%|          | 232/137328 [00:00<00:59, 2312.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.59612306]]\n",
      "normalized log_p: [[-100.60287292]]\n",
      "convergence gap: [[0.00674986]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2369.12it/s]\n",
      "  0%|          | 212/137328 [00:00<01:04, 2114.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.59038839]]\n",
      "normalized log_p: [[-100.59612306]]\n",
      "convergence gap: [[0.00573467]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2393.70it/s]\n",
      "  0%|          | 480/137328 [00:00<00:57, 2388.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.58550713]]\n",
      "normalized log_p: [[-100.59038839]]\n",
      "convergence gap: [[0.00488125]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2389.34it/s]\n",
      "  0%|          | 243/137328 [00:00<00:56, 2425.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.58134493]]\n",
      "normalized log_p: [[-100.58550713]]\n",
      "convergence gap: [[0.0041622]]\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2383.90it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2131.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57778972]]\n",
      "normalized log_p: [[-100.58134493]]\n",
      "convergence gap: [[0.00355521]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2383.01it/s]\n",
      "  0%|          | 481/137328 [00:00<00:57, 2378.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57474776]]\n",
      "normalized log_p: [[-100.57778972]]\n",
      "convergence gap: [[0.00304196]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2361.97it/s]\n",
      "  0%|          | 494/137328 [00:00<00:55, 2444.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57214044]]\n",
      "normalized log_p: [[-100.57474776]]\n",
      "convergence gap: [[0.00260732]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2368.75it/s]\n",
      "  0%|          | 244/137328 [00:00<00:56, 2434.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56990174]]\n",
      "normalized log_p: [[-100.57214044]]\n",
      "convergence gap: [[0.0022387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2366.04it/s]\n",
      "  0%|          | 480/137328 [00:00<00:57, 2376.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5679761]]\n",
      "normalized log_p: [[-100.56990174]]\n",
      "convergence gap: [[0.00192564]]\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:57<00:00, 2384.67it/s]\n",
      "  0%|          | 245/137328 [00:00<00:56, 2442.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56631673]]\n",
      "normalized log_p: [[-100.5679761]]\n",
      "convergence gap: [[0.00165937]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2324.70it/s]\n",
      "  0%|          | 216/137328 [00:00<01:03, 2152.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56488416]]\n",
      "normalized log_p: [[-100.56631673]]\n",
      "convergence gap: [[0.00143256]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2240.57it/s]\n",
      "  0%|          | 242/137328 [00:00<00:56, 2419.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5636451]]\n",
      "normalized log_p: [[-100.56488416]]\n",
      "convergence gap: [[0.00123906]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2269.26it/s]\n",
      "  0%|          | 201/137328 [00:00<01:08, 2002.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56257138]]\n",
      "normalized log_p: [[-100.5636451]]\n",
      "convergence gap: [[0.00107372]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1977.95it/s]\n",
      "  0%|          | 373/137328 [00:00<01:11, 1911.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56163917]]\n",
      "normalized log_p: [[-100.56257138]]\n",
      "convergence gap: [[0.00093221]]\n",
      "iteration: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2218.31it/s]\n",
      "  0%|          | 211/137328 [00:00<01:05, 2103.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56082829]]\n",
      "normalized log_p: [[-100.56163917]]\n",
      "convergence gap: [[0.00081088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2232.80it/s]\n",
      "  0%|          | 482/137328 [00:00<00:57, 2389.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56012163]]\n",
      "normalized log_p: [[-100.56082829]]\n",
      "convergence gap: [[0.00070667]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2241.42it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2129.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55950462]]\n",
      "normalized log_p: [[-100.56012163]]\n",
      "convergence gap: [[0.00061701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2239.37it/s]\n",
      "  0%|          | 236/137328 [00:00<00:58, 2357.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5589649]]\n",
      "normalized log_p: [[-100.55950462]]\n",
      "convergence gap: [[0.00053972]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2253.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55849192]]\n",
      "normalized log_p: [[-100.5589649]]\n",
      "convergence gap: [[0.00047298]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float64)\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print('normalized log_p_hat:', (log_p_hat/n).numpy())\n",
    "    print('normalized log_p:', (log_p/n).numpy())\n",
    "    print('convergence gap:', (log_p_hat/n - log_p/n).numpy())\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 iterations, ~35 min\n",
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for t in tqdm(range(n)):\n",
    "        movie_ids_t = t_movie_ids_labels_dict[t]\n",
    "        labels_t = t_labels_dict[t]\n",
    "\n",
    "        # calculate X_t_hat\n",
    "        y_t = t_y_dict[t]\n",
    "        H_xt = t_Hx_dict[t]\n",
    "        H_xt_trans = t_Hx_trans_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        R_xt = H_xt @ R @ H_xt_trans\n",
    "        R_yt = H_yt @ R @ H_yt_trans\n",
    "        R_yt_inv = tf.linalg.inv(R_yt)\n",
    "        R_xtyt = H_xt @ R @ H_yt_trans\n",
    "        \n",
    "        mu_yt = tf.matmul(H_yt, mu)\n",
    "        mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "        X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "        \n",
    "        # clip ratings\n",
    "        predictions_t = tf.matmul(H_xt_trans, X_t_hat).numpy()[movie_ids_t-1]\n",
    "        predictions_t = np.clip(predictions_t, 1, 5)\n",
    "        \n",
    "        # accumulate square_error and l\n",
    "        square_error += tf.matmul(tf.transpose(labels_t - predictions_t), labels_t - predictions_t)\n",
    "        l += len(labels_t)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [02:02<00:00, 1121.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07507623]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_mu = np.load('results/em_mu.npy')\n",
    "em_R = np.load('results/em_R.npy')\n",
    "rmse = evaluate(em_mu, em_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:58<00:00, 1159.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07510565]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
