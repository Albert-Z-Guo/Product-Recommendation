{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation\n",
    "Reference: https://ieeexplore.ieee.org/document/5430993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = pd.read_csv('data/Y.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "P_data = pd.read_csv('data/P.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       5      2     1\n",
       "1       4      7     1\n",
       "2       4      8     1\n",
       "3       4     11     1\n",
       "4       4     12     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       3      6     1\n",
       "1       5     96     1\n",
       "2       3      1     2\n",
       "3       3     33     3\n",
       "4       5     42     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((3399874, 3), (189699, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())\n",
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100 137328\n",
      "5 100 137328\n"
     ]
    }
   ],
   "source": [
    "print(Y_data['Rating'].unique().max(), Y_data['Movie'].unique().max(), Y_data['User'].unique().max())\n",
    "print(P_data['Rating'].unique().max(), P_data['Movie'].unique().max(), P_data['User'].unique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 137328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = Y_data['Movie'].unique().max(), Y_data['User'].unique().max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_sparse = tf.SparseTensor(indices=Y_data[['Movie', 'User']].values-1, values=Y_data['Rating'].values, dense_shape=[k, n])\n",
    "Z_sparse = tf.cast(Z_sparse, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 137328), dtype=float64, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 3.],\n",
       "       [0., 0., 0., ..., 3., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 4., 0., 4.],\n",
       "       [4., 0., 3., ..., 0., 0., 4.],\n",
       "       [3., 4., 0., ..., 4., 5., 4.]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dense matrices for faster linear transformations since all matrices can fit in memory\n",
    "Z = tf.sparse.to_dense(Z_sparse, validate_indices=False)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [10:42<00:00, 213.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# memoization\n",
    "t_k_dict = {}\n",
    "t_Z_dict = {}\n",
    "t_y_dict = {}\n",
    "t_x_dict = {}\n",
    "t_Hy_dict = {}\n",
    "t_Hx_dict = {}\n",
    "t_Hy_trans_dict = {}\n",
    "t_Hx_trans_dict = {}\n",
    "t_movie_ids_dict = {}\n",
    "t_labels_dict = {}\n",
    "\n",
    "Y_data_user_ids = Y_data['User'].values\n",
    "P_data_user_ids = P_data['User'].values\n",
    "\n",
    "for t in tqdm(range(n)):\n",
    "    movie_ids_indices = Y_data[ne.evaluate(f'Y_data_user_ids == {t+1}')]['Movie'].values - 1\n",
    "    H_yt = tf.constant(np.identity(k)[movie_ids_indices], dtype=tf.float64)\n",
    "    H_xt = tf.constant(np.delete(np.identity(k), movie_ids_indices, 0), dtype=tf.float64)\n",
    "    \n",
    "    k_t = tf.constant(H_yt.shape[0], dtype=tf.float64)\n",
    "    Z_t = tf.expand_dims(Z[:, t], axis=1) \n",
    "    y_t = tf.matmul(H_yt, Z_t)\n",
    "    x_t = tf.matmul(H_xt, Z_t)\n",
    "    \n",
    "    # store the variables for fast future reference\n",
    "    t_Hy_dict[t] = H_yt\n",
    "    t_Hx_dict[t] = H_xt\n",
    "    t_Hx_trans_dict[t] = tf.transpose(H_xt)\n",
    "    t_Hy_trans_dict[t] = tf.transpose(H_yt)\n",
    "    \n",
    "    t_k_dict[t] = k_t\n",
    "    t_x_dict[t] = x_t\n",
    "    t_y_dict[t] = y_t\n",
    "    t_Z_dict[t] = Z_t\n",
    "    \n",
    "    t_movie_ids_dict[t] = P_data[ne.evaluate(f'P_data_user_ids == {t+1}')]['Movie'].values\n",
    "    t_labels_dict[t] = tf.expand_dims(P_data[ne.evaluate(f'P_data_user_ids == {t+1}')]['Rating'].values, axis=1)\n",
    "    \n",
    "del Y_data\n",
    "del P_data\n",
    "del Z_sparse\n",
    "del Y_data_user_ids\n",
    "del P_data_user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "$\\mu$ has 1 type available <br />\n",
    "R has 4 types available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:17<00:00, 8070.88it/s] \n"
     ]
    }
   ],
   "source": [
    "# initial estimate of mu\n",
    "N = 0\n",
    "H_yty_t = 0\n",
    "\n",
    "for t in tqdm(range(n)):\n",
    "    N += tf.matmul(t_Hy_trans_dict[t], t_Hy_dict[t])\n",
    "    H_yty_t += tf.matmul(t_Hy_trans_dict[t], t_y_dict[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[20017.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0., 23917.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0.,     0., 31634., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [    0.,     0.,     0., ..., 60896.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0., 61521.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0., 64506.]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=float64, numpy=\n",
       "array([[3.45266523, 3.57674457, 3.28788645, 3.90478757, 3.79035475,\n",
       "        3.44415598, 3.19071562, 4.52835008, 3.82013753, 3.6159503 ,\n",
       "        3.40382731, 3.83725101, 4.07603884, 4.22836664, 3.35395465,\n",
       "        4.0645276 , 3.72119599, 3.48700861, 4.16388921, 3.40982441,\n",
       "        3.86926003, 3.43583485, 3.20324443, 4.08487897, 3.23199846,\n",
       "        3.88664794, 4.33189497, 4.38358165, 4.31638739, 3.86591733,\n",
       "        4.33975717, 3.89147883, 3.70029269, 3.36247781, 4.32901523,\n",
       "        4.06706884, 4.56922029, 3.77104091, 3.68586682, 3.84532386,\n",
       "        4.3454114 , 3.90999207, 3.39949928, 3.60786807, 3.96267104,\n",
       "        4.14386102, 3.4072049 , 3.7040225 , 4.00350359, 4.64280228,\n",
       "        3.21623279, 3.77238583, 4.26565116, 4.45377313, 3.83848945,\n",
       "        3.79374176, 3.7629172 , 3.88698608, 3.80041727, 4.34696995,\n",
       "        3.80469565, 3.84624795, 3.64122601, 3.27221683, 3.42333499,\n",
       "        3.71631568, 3.20698918, 4.45410441, 4.26541296, 3.86109184,\n",
       "        4.48300912, 4.36214633, 3.53881394, 4.11710733, 3.89469836,\n",
       "        3.36079261, 4.17943046, 3.57937229, 3.63978239, 3.97593945,\n",
       "        3.75073493, 3.82111027, 4.0340625 , 3.95830124, 3.49137664,\n",
       "        3.47419713, 3.82147924, 3.64295837, 3.47428571, 3.63893732,\n",
       "        3.45263392, 3.50476104, 4.36729116, 4.36178889, 4.01151688,\n",
       "        4.19239538, 3.48068086, 3.85856214, 3.80258773, 3.38737482]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_hat0 = tf.matmul(tf.linalg.inv(N), H_yty_t)\n",
    "tf.transpose(mu_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.constant(np.identity(k), dtype=tf.float64)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:31<00:00, 4358.03it/s]\n"
     ]
    }
   ],
   "source": [
    "S = 0\n",
    "for t in tqdm(range(n)):\n",
    "    Hyt = t_Hy_dict[t]\n",
    "    yt = t_y_dict[t]\n",
    "    Hytmu_hat0 = tf.matmul(Hyt, mu_hat0)\n",
    "    S += tf.transpose(Hyt) @ (yt - Hytmu_hat0) @ tf.transpose(yt - Hytmu_hat0) @ Hyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[1.72440427, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.94219113, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.43659411, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.18291506, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.03485685,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.26227449]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(tf.linalg.inv(N), diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[ 1.        ,  0.07418256, -0.01158277, ..., -0.01462987,\n",
       "        -0.02215371, -0.01844816],\n",
       "       [ 0.07418256,  1.        ,  0.03674347, ...,  0.0256191 ,\n",
       "         0.03563234,  0.03926307],\n",
       "       [-0.01158277,  0.03674347,  1.        , ...,  0.10955311,\n",
       "         0.12823359,  0.15560634],\n",
       "       ...,\n",
       "       [-0.01462987,  0.0256191 ,  0.10955311, ...,  1.        ,\n",
       "         0.19781317,  0.15164928],\n",
       "       [-0.02215371,  0.03563234,  0.12823359, ...,  0.19781317,\n",
       "         1.        ,  0.18995689],\n",
       "       [-0.01844816,  0.03926307,  0.15560634, ...,  0.15164928,\n",
       "         0.18995689,  1.        ]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "R_hat0_3 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(diag_S)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(diag_S))))\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[ 1.72440427,  0.09455639, -0.01823052, ..., -0.02089473,\n",
       "        -0.02959417, -0.02721758],\n",
       "       [ 0.09455639,  0.94219113,  0.04274809, ...,  0.02704644,\n",
       "         0.03518471,  0.04281842],\n",
       "       [-0.01823052,  0.04274809,  1.43659411, ...,  0.14281326,\n",
       "         0.15635399,  0.20954206],\n",
       "       ...,\n",
       "       [-0.02089473,  0.02704644,  0.14281326, ...,  1.18291506,\n",
       "         0.21886288,  0.18530794],\n",
       "       [-0.02959417,  0.03518471,  0.15635399, ...,  0.21886288,\n",
       "         1.03485685,  0.21710614],\n",
       "       [-0.02721758,  0.04281842,  0.20954206, ...,  0.18530794,\n",
       "         0.21710614,  1.26227449]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat0_4 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(N)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(N))))\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float64))\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans, k_t):\n",
    "    # for R estimation\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    Z_t_hat = H_yt_trans @ y_t + H_xt_trans @ X_t_hat\n",
    "    \n",
    "    R_hat_sum_part = (Z_t_hat - mu) @ tf.transpose(Z_t_hat - mu) \\\n",
    "                        + H_xt_trans @ (R_xt - R_xtyt @ R_yt_inv @ tf.transpose(R_xtyt)) @ H_xt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k_t*LOG_2PI) \n",
    "    \n",
    "    return R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(mu, R):\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    R_hat_sum = 0\n",
    "    log_p_hat = 0\n",
    "    \n",
    "    for t in tqdm(range(n)):\n",
    "        k_t = t_k_dict[t]\n",
    "        y_t = t_y_dict[t]\n",
    "        H_xt = t_Hx_dict[t]\n",
    "        H_xt_trans = t_Hx_trans_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans, k_t)\n",
    "        \n",
    "        R_hat_sum += R_hat_sum_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R_hat_sum / n\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)    \n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/137328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:49<00:00, 1258.18it/s]\n",
      "  0%|          | 136/137328 [00:00<01:40, 1358.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-32.23267267]]\n",
      "normalized log_p: -inf\n",
      "convergence gap: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:37<00:00, 1403.04it/s]\n",
      "  0%|          | 149/137328 [00:00<01:32, 1486.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.93570812]]\n",
      "normalized log_p: [[-32.23267267]]\n",
      "convergence gap: [[0.29696454]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:33<00:00, 1473.69it/s]\n",
      "  0%|          | 151/137328 [00:00<01:30, 1507.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.78397177]]\n",
      "normalized log_p: [[-31.93570812]]\n",
      "convergence gap: [[0.15173636]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:35<00:00, 1443.61it/s]\n",
      "  0%|          | 133/137328 [00:00<01:43, 1322.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.68821476]]\n",
      "normalized log_p: [[-31.78397177]]\n",
      "convergence gap: [[0.09575701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:37<00:00, 1413.79it/s]\n",
      "  0%|          | 151/137328 [00:00<01:30, 1508.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.62162646]]\n",
      "normalized log_p: [[-31.68821476]]\n",
      "convergence gap: [[0.0665883]]\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:29<00:00, 1534.95it/s]\n",
      "  0%|          | 164/137328 [00:00<01:23, 1634.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.57324325]]\n",
      "normalized log_p: [[-31.62162646]]\n",
      "convergence gap: [[0.04838321]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1506.45it/s]\n",
      "  0%|          | 160/137328 [00:00<01:26, 1593.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.53722374]]\n",
      "normalized log_p: [[-31.57324325]]\n",
      "convergence gap: [[0.03601951]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1574.22it/s]\n",
      "  0%|          | 153/137328 [00:00<01:29, 1528.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.50996466]]\n",
      "normalized log_p: [[-31.53722374]]\n",
      "convergence gap: [[0.02725908]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1525.77it/s]\n",
      "  0%|          | 118/137328 [00:00<01:56, 1173.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.48908709]]\n",
      "normalized log_p: [[-31.50996466]]\n",
      "convergence gap: [[0.02087757]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:53<00:00, 1209.76it/s]\n",
      "  0%|          | 116/137328 [00:00<01:58, 1156.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.47295385]]\n",
      "normalized log_p: [[-31.48908709]]\n",
      "convergence gap: [[0.01613325]]\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:52<00:00, 1220.27it/s]\n",
      "  0%|          | 81/137328 [00:00<02:50, 805.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.4604017]]\n",
      "normalized log_p: [[-31.47295385]]\n",
      "convergence gap: [[0.01255214]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:46<00:00, 1294.82it/s]\n",
      "  0%|          | 147/137328 [00:00<01:33, 1469.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.4505828]]\n",
      "normalized log_p: [[-31.4604017]]\n",
      "convergence gap: [[0.0098189]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:37<00:00, 1413.13it/s]\n",
      "  0%|          | 124/137328 [00:00<01:51, 1233.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.44286679]]\n",
      "normalized log_p: [[-31.4505828]]\n",
      "convergence gap: [[0.00771601]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1520.02it/s]\n",
      "  0%|          | 153/137328 [00:00<01:29, 1528.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.43677819]]\n",
      "normalized log_p: [[-31.44286679]]\n",
      "convergence gap: [[0.00608859]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1555.99it/s]\n",
      "  0%|          | 163/137328 [00:00<01:24, 1627.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.43195469]]\n",
      "normalized log_p: [[-31.43677819]]\n",
      "convergence gap: [[0.0048235]]\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1514.08it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1583.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42811827]]\n",
      "normalized log_p: [[-31.43195469]]\n",
      "convergence gap: [[0.00383642]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1551.73it/s]\n",
      "  0%|          | 164/137328 [00:00<01:24, 1630.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42505464]]\n",
      "normalized log_p: [[-31.42811827]]\n",
      "convergence gap: [[0.00306364]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1586.23it/s]\n",
      "  0%|          | 154/137328 [00:00<01:29, 1529.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42259802]]\n",
      "normalized log_p: [[-31.42505464]]\n",
      "convergence gap: [[0.00245661]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:38<00:00, 1396.03it/s]\n",
      "  0%|          | 148/137328 [00:00<01:33, 1470.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42061987]]\n",
      "normalized log_p: [[-31.42259802]]\n",
      "convergence gap: [[0.00197815]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:32<00:00, 1480.24it/s]\n",
      "  0%|          | 165/137328 [00:00<01:23, 1646.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41902021]]\n",
      "normalized log_p: [[-31.42061987]]\n",
      "convergence gap: [[0.00159966]]\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1511.99it/s]\n",
      "  0%|          | 132/137328 [00:00<01:44, 1311.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41772109]]\n",
      "normalized log_p: [[-31.41902021]]\n",
      "convergence gap: [[0.00129912]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:32<00:00, 1491.43it/s]\n",
      "  0%|          | 141/137328 [00:00<01:37, 1400.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41666156]]\n",
      "normalized log_p: [[-31.41772109]]\n",
      "convergence gap: [[0.00105952]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:32<00:00, 1486.98it/s]\n",
      "  0%|          | 158/137328 [00:00<01:27, 1572.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41579382]]\n",
      "normalized log_p: [[-31.41666156]]\n",
      "convergence gap: [[0.00086775]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:29<00:00, 1542.02it/s]\n",
      "  0%|          | 148/137328 [00:00<01:33, 1470.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41508021]]\n",
      "normalized log_p: [[-31.41579382]]\n",
      "convergence gap: [[0.00071361]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1552.28it/s]\n",
      "  0%|          | 157/137328 [00:00<01:27, 1564.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41449099]]\n",
      "normalized log_p: [[-31.41508021]]\n",
      "convergence gap: [[0.00058921]]\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1497.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41400258]]\n",
      "normalized log_p: [[-31.41449099]]\n",
      "convergence gap: [[0.00048841]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float64)\n",
    "\n",
    "for i in range(30):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = expectation_maximization(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print('normalized log_p_hat:', (log_p_hat/n).numpy())\n",
    "    print('normalized log_p:', (log_p/n).numpy())\n",
    "    print('convergence gap:', (log_p_hat/n - log_p/n).numpy())\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 iterations, ~38 min\n",
    "np.save('results/em_mu.npy', mu_hat)\n",
    "np.save('results/em_R.npy', R_hat)\n",
    "np.save('results/em_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McMichael’s Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans, k_t):\n",
    "    # for R estimation\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k_t*LOG_2PI)\n",
    "    \n",
    "    return log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "\n",
    "    for t in tqdm(range(n)):\n",
    "        k_t = t_k_dict[t]\n",
    "        y_t = t_y_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans, k_t)\n",
    "        \n",
    "        log_p_gradient += log_p_gradient_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/137328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:06<00:00, 2057.72it/s]\n",
      "  0%|          | 167/137328 [00:00<01:22, 1662.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-32.23267267]]\n",
      "normalized log_p: -inf\n",
      "convergence gap: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:04<00:00, 2144.22it/s]\n",
      "  0%|          | 149/137328 [00:00<01:32, 1481.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-32.00694536]]\n",
      "normalized log_p: [[-32.23267267]]\n",
      "convergence gap: [[0.2257273]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:07<00:00, 2024.04it/s]\n",
      "  0%|          | 196/137328 [00:00<01:10, 1948.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.87427149]]\n",
      "normalized log_p: [[-32.00694536]]\n",
      "convergence gap: [[0.13267387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2160.43it/s]\n",
      "  0%|          | 162/137328 [00:00<01:24, 1613.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.78281261]]\n",
      "normalized log_p: [[-31.87427149]]\n",
      "convergence gap: [[0.09145888]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:09<00:00, 1977.84it/s]\n",
      "  0%|          | 219/137328 [00:00<01:02, 2182.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.71493972]]\n",
      "normalized log_p: [[-31.78281261]]\n",
      "convergence gap: [[0.06787289]]\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:05<00:00, 2085.64it/s]\n",
      "  0%|          | 190/137328 [00:00<01:12, 1897.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.66230112]]\n",
      "normalized log_p: [[-31.71493972]]\n",
      "convergence gap: [[0.0526386]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2183.43it/s]\n",
      "  0%|          | 237/137328 [00:00<00:58, 2361.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.62041707]]\n",
      "normalized log_p: [[-31.66230112]]\n",
      "convergence gap: [[0.04188405]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2280.62it/s]\n",
      "  0%|          | 235/137328 [00:00<00:58, 2342.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.58655052]]\n",
      "normalized log_p: [[-31.62041707]]\n",
      "convergence gap: [[0.03386655]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2242.20it/s]\n",
      "  0%|          | 238/137328 [00:00<00:57, 2379.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.55885959]]\n",
      "normalized log_p: [[-31.58655052]]\n",
      "convergence gap: [[0.02769093]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2296.82it/s]\n",
      "  0%|          | 234/137328 [00:00<00:58, 2329.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.53602707]]\n",
      "normalized log_p: [[-31.55885959]]\n",
      "convergence gap: [[0.02283252]]\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2231.56it/s]\n",
      "  0%|          | 204/137328 [00:00<01:07, 2037.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.51707512]]\n",
      "normalized log_p: [[-31.53602707]]\n",
      "convergence gap: [[0.01895195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:10<00:00, 1937.95it/s]\n",
      "  0%|          | 230/137328 [00:00<00:59, 2297.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.50125945]]\n",
      "normalized log_p: [[-31.51707512]]\n",
      "convergence gap: [[0.01581567]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2193.52it/s]\n",
      "  0%|          | 218/137328 [00:00<01:02, 2177.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.48800287]]\n",
      "normalized log_p: [[-31.50125945]]\n",
      "convergence gap: [[0.01325658]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2209.73it/s]\n",
      "  0%|          | 236/137328 [00:00<00:58, 2357.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.47685087]]\n",
      "normalized log_p: [[-31.48800287]]\n",
      "convergence gap: [[0.01115201]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:05<00:00, 2111.39it/s]\n",
      "  0%|          | 195/137328 [00:00<01:10, 1941.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.46744078]]\n",
      "normalized log_p: [[-31.47685087]]\n",
      "convergence gap: [[0.00941008]]\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:06<00:00, 2079.66it/s]\n",
      "  0%|          | 215/137328 [00:00<01:03, 2147.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.45948]]\n",
      "normalized log_p: [[-31.46744078]]\n",
      "convergence gap: [[0.00796078]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2257.24it/s]\n",
      "  0%|          | 236/137328 [00:00<00:58, 2353.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.45273014]]\n",
      "normalized log_p: [[-31.45948]]\n",
      "convergence gap: [[0.00674986]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2256.51it/s]\n",
      "  0%|          | 232/137328 [00:00<00:59, 2318.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.44699547]]\n",
      "normalized log_p: [[-31.45273014]]\n",
      "convergence gap: [[0.00573467]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:05<00:00, 2103.95it/s]\n",
      "  0%|          | 217/137328 [00:00<01:03, 2169.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.44211422]]\n",
      "normalized log_p: [[-31.44699547]]\n",
      "convergence gap: [[0.00488125]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2192.72it/s]\n",
      "  0%|          | 231/137328 [00:00<00:59, 2305.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.43795202]]\n",
      "normalized log_p: [[-31.44211422]]\n",
      "convergence gap: [[0.0041622]]\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2166.93it/s]\n",
      "  0%|          | 236/137328 [00:00<00:58, 2358.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.43439681]]\n",
      "normalized log_p: [[-31.43795202]]\n",
      "convergence gap: [[0.00355521]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2153.81it/s]\n",
      "  0%|          | 229/137328 [00:00<00:59, 2289.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.43135485]]\n",
      "normalized log_p: [[-31.43439681]]\n",
      "convergence gap: [[0.00304196]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2174.89it/s]\n",
      "  0%|          | 232/137328 [00:00<00:59, 2310.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42874753]]\n",
      "normalized log_p: [[-31.43135485]]\n",
      "convergence gap: [[0.00260732]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2244.48it/s]\n",
      "  0%|          | 228/137328 [00:00<01:00, 2272.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42650882]]\n",
      "normalized log_p: [[-31.42874753]]\n",
      "convergence gap: [[0.0022387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2215.74it/s]\n",
      "  0%|          | 204/137328 [00:00<01:07, 2032.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42458318]]\n",
      "normalized log_p: [[-31.42650882]]\n",
      "convergence gap: [[0.00192564]]\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:06<00:00, 2069.16it/s]\n",
      "  0%|          | 235/137328 [00:00<00:58, 2347.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42292381]]\n",
      "normalized log_p: [[-31.42458318]]\n",
      "convergence gap: [[0.00165937]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2199.75it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2135.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42149125]]\n",
      "normalized log_p: [[-31.42292381]]\n",
      "convergence gap: [[0.00143256]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2269.84it/s]\n",
      "  0%|          | 232/137328 [00:00<00:59, 2312.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.42025219]]\n",
      "normalized log_p: [[-31.42149125]]\n",
      "convergence gap: [[0.00123906]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2177.77it/s]\n",
      "  0%|          | 213/137328 [00:00<01:04, 2129.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41917846]]\n",
      "normalized log_p: [[-31.42025219]]\n",
      "convergence gap: [[0.00107372]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:05<00:00, 2083.87it/s]\n",
      "  0%|          | 209/137328 [00:00<01:05, 2079.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41824626]]\n",
      "normalized log_p: [[-31.41917846]]\n",
      "convergence gap: [[0.00093221]]\n",
      "iteration: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2267.79it/s]\n",
      "  0%|          | 231/137328 [00:00<00:59, 2306.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41743538]]\n",
      "normalized log_p: [[-31.41824626]]\n",
      "convergence gap: [[0.00081088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2163.14it/s]\n",
      "  0%|          | 238/137328 [00:00<00:57, 2371.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41672871]]\n",
      "normalized log_p: [[-31.41743538]]\n",
      "convergence gap: [[0.00070667]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:04<00:00, 2127.88it/s]\n",
      "  0%|          | 223/137328 [00:00<01:01, 2226.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41611171]]\n",
      "normalized log_p: [[-31.41672871]]\n",
      "convergence gap: [[0.00061701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2170.82it/s]\n",
      "  0%|          | 226/137328 [00:00<01:00, 2258.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.41557199]]\n",
      "normalized log_p: [[-31.41611171]]\n",
      "convergence gap: [[0.00053972]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:06<00:00, 2074.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-31.415099]]\n",
      "normalized log_p: [[-31.41557199]]\n",
      "convergence gap: [[0.00047298]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float64)\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print('normalized log_p_hat:', (log_p_hat/n).numpy())\n",
    "    print('normalized log_p:', (log_p/n).numpy())\n",
    "    print('convergence gap:', (log_p_hat/n - log_p/n).numpy())\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 iterations, ~38 min\n",
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_square_error(mu, R, movie_ids_t, labels_t, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans):\n",
    "    # calculate X_t_hat\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    \n",
    "    # clip ratings\n",
    "    predictions_t = tf.gather(tf.matmul(H_xt_trans, X_t_hat), indices=movie_ids_t-1)\n",
    "    predictions_t = tf.clip_by_value(predictions_t, 1, 5)\n",
    "    \n",
    "    return tf.matmul(tf.transpose(labels_t - predictions_t), labels_t - predictions_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for t in tqdm(range(n)):\n",
    "        movie_ids_t = t_movie_ids_dict[t]\n",
    "        labels_t = tf.cast(t_labels_dict[t], dtype=tf.float64)\n",
    "\n",
    "        y_t = t_y_dict[t]\n",
    "        H_xt = t_Hx_dict[t]\n",
    "        H_xt_trans = t_Hx_trans_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "                \n",
    "        # accumulate square_error and l\n",
    "        square_error += run_graph_square_error(mu, R, movie_ids_t, labels_t, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans)\n",
    "        l += len(labels_t)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1654.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91700701]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_mu = np.load('results/em_mu.npy')\n",
    "em_R = np.load('results/em_R.npy')\n",
    "rmse = evaluate(em_mu, em_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:12<00:00, 1897.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91701472]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
