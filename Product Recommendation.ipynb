{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation\n",
    "Reference: https://ieeexplore.ieee.org/document/5430993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = pd.read_csv('data/Y.csv', header=None, names=['Rating','Movie','User'], dtype=int) # training data\n",
    "P_data = pd.read_csv('data/P.csv', header=None, names=['Rating','Movie','User'], dtype=int) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       5      2     1\n",
       "1       4      7     1\n",
       "2       4      8     1\n",
       "3       4     11     1\n",
       "4       4     12     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       3      6     1\n",
       "1       5     96     1\n",
       "2       3      1     2\n",
       "3       3     33     3\n",
       "4       5     42     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3399874, 3), (189699, 3))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100 137328\n",
      "5 100 137328\n"
     ]
    }
   ],
   "source": [
    "print(Y_data['Rating'].unique().max(), Y_data['Movie'].unique().max(), Y_data['User'].unique().max())\n",
    "print(P_data['Rating'].unique().max(), P_data['Movie'].unique().max(), P_data['User'].unique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 137328)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = Y_data['Movie'].unique().max(), Y_data['User'].unique().max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3399874, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[     1,      0],\n",
       "       [     6,      0],\n",
       "       [     7,      0],\n",
       "       ...,\n",
       "       [    97, 137327],\n",
       "       [    98, 137327],\n",
       "       [    99, 137327]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.reshape(Y_data[['Movie', 'User']].values-1, (-1, 2))\n",
    "print(indices.shape)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_sparse = tf.SparseTensor(indices=indices, values=Y_data['Rating'].values, dense_shape=[k, n])\n",
    "Z_sparse = tf.cast(Z_sparse, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 ms, sys: 1.05 ms, total: 20.3 ms\n",
      "Wall time: 18.8 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# t = 0\n",
    "# Z_t = tf.sparse.slice(Z_sparse, [0, t], [100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 137328), dtype=float64, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 3.],\n",
       "       [0., 0., 0., ..., 3., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 4., 0., 4.],\n",
       "       [4., 0., 3., ..., 0., 0., 4.],\n",
       "       [3., 4., 0., ..., 4., 5., 4.]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dense matrices for faster linear transformations since all matrices can fit in memory\n",
    "Z = tf.sparse.to_dense(Z_sparse, validate_indices=False)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [13:45<00:00, 166.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# memoization\n",
    "t_Z_dict = {}\n",
    "t_y_dict = {}\n",
    "t_x_dict = {}\n",
    "t_Hy_dict = {}\n",
    "t_Hx_dict = {}\n",
    "t_Hy_trans_dict = {}\n",
    "t_Hx_trans_dict = {}\n",
    "t_movie_ids_labels_dict = {}\n",
    "t_labels_dict = {}\n",
    "\n",
    "for t in tqdm(range(n)):\n",
    "    movie_ids = Y_data['Movie'][Y_data['User']==t+1].values\n",
    "    H_yt = tf.constant(np.identity(k)[movie_ids-1], dtype=tf.float64)\n",
    "    H_xt = tf.constant(np.delete(np.identity(k), movie_ids-1, 0), dtype=tf.float64)\n",
    "    Z_t = tf.expand_dims(Z[:, t], axis=1) # alternative: Z_t = tf.sparse.slice(Z_sparse, [0, t], [100, 1]) \n",
    "    y_t = tf.matmul(H_yt, Z_t)\n",
    "    x_t = tf.matmul(H_xt, Z_t)\n",
    "    \n",
    "    # store the variables for fast future reference\n",
    "    t_Hy_dict[t] = H_yt\n",
    "    t_Hx_dict[t] = H_xt\n",
    "    t_Hx_trans_dict[t] = tf.transpose(H_xt)\n",
    "    t_Hy_trans_dict[t] = tf.transpose(H_yt)\n",
    "    \n",
    "    t_x_dict[t] = x_t\n",
    "    t_y_dict[t] = y_t\n",
    "    t_Z_dict[t] = Z_t\n",
    "    \n",
    "    t_movie_ids_labels_dict[t] = P_data['Movie'][P_data['User']==t+1].values\n",
    "    t_labels_dict[t] = tf.expand_dims(P_data['Rating'][P_data['User']==t+1].values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "$\\mu$ has 1 type available <br />\n",
    "R has 4 types available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:15<00:00, 8605.84it/s] \n"
     ]
    }
   ],
   "source": [
    "# initial estimate of mu\n",
    "N = 0\n",
    "H_yty_t = 0\n",
    "\n",
    "for t in tqdm(range(n)):\n",
    "    N += tf.matmul(t_Hy_trans_dict[t], t_Hy_dict[t])\n",
    "    H_yty_t += tf.matmul(t_Hy_trans_dict[t], t_y_dict[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[20017.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0., 23917.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0.,     0., 31634., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [    0.,     0.,     0., ..., 60896.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0., 61521.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0., 64506.]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(H_yty_t.shape)\n",
    "mu_hat0 = tf.matmul(tf.linalg.inv(N), H_yty_t)\n",
    "mu_hat0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.constant(np.identity(k), dtype=tf.float64)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:31<00:00, 4384.91it/s]\n"
     ]
    }
   ],
   "source": [
    "S = 0\n",
    "for t in tqdm(range(n)):\n",
    "    Hyt = t_Hy_dict[t]\n",
    "    yt = t_y_dict[t]\n",
    "    Hytmu_hat0 = tf.matmul(Hyt, mu_hat0)\n",
    "    S += tf.matmul(tf.transpose(Hyt), tf.matmul(yt - Hytmu_hat0, tf.matmul(tf.transpose(yt - Hytmu_hat0), Hyt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[1.72440427, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.94219113, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.43659411, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.18291506, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.03485685,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.26227449]])>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(tf.linalg.inv(N), diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[ 1.        ,  0.07418256, -0.01158277, ..., -0.01462987,\n",
       "        -0.02215371, -0.01844816],\n",
       "       [ 0.07418256,  1.        ,  0.03674347, ...,  0.0256191 ,\n",
       "         0.03563234,  0.03926307],\n",
       "       [-0.01158277,  0.03674347,  1.        , ...,  0.10955311,\n",
       "         0.12823359,  0.15560634],\n",
       "       ...,\n",
       "       [-0.01462987,  0.0256191 ,  0.10955311, ...,  1.        ,\n",
       "         0.19781317,  0.15164928],\n",
       "       [-0.02215371,  0.03563234,  0.12823359, ...,  0.19781317,\n",
       "         1.        ,  0.18995689],\n",
       "       [-0.01844816,  0.03926307,  0.15560634, ...,  0.15164928,\n",
       "         0.18995689,  1.        ]])>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "R_hat0_3 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(diag_S)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(diag_S))))\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float64, numpy=\n",
       "array([[ 1.72440427,  0.09455639, -0.01823052, ..., -0.02089473,\n",
       "        -0.02959417, -0.02721758],\n",
       "       [ 0.09455639,  0.94219113,  0.04274809, ...,  0.02704644,\n",
       "         0.03518471,  0.04281842],\n",
       "       [-0.01823052,  0.04274809,  1.43659411, ...,  0.14281326,\n",
       "         0.15635399,  0.20954206],\n",
       "       ...,\n",
       "       [-0.02089473,  0.02704644,  0.14281326, ...,  1.18291506,\n",
       "         0.21886288,  0.18530794],\n",
       "       [-0.02959417,  0.03518471,  0.15635399, ...,  0.21886288,\n",
       "         1.03485685,  0.21710614],\n",
       "       [-0.02721758,  0.04281842,  0.20954206, ...,  0.18530794,\n",
       "         0.21710614,  1.26227449]])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat0_4 = tf.matmul(tf.linalg.sqrtm(tf.linalg.inv(N)), tf.matmul(S, tf.linalg.sqrtm(tf.linalg.inv(N))))\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float64))\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans):\n",
    "    # for R estimation\n",
    "    R_xt = H_xt @ R @ H_xt_trans\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    Z_t_hat = H_yt_trans @ y_t + H_xt_trans @ X_t_hat\n",
    "    \n",
    "    R_hat_sum_part = (Z_t_hat - mu) @ tf.transpose(Z_t_hat - mu) \\\n",
    "                        + H_xt_trans @ (R_xt - R_xtyt @ R_yt_inv @ tf.transpose(R_xtyt)) @ H_xt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "\n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k*LOG_2PI) \n",
    "    \n",
    "    return R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(mu, R):\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    R_hat_sum = 0\n",
    "    log_p_hat = 0\n",
    "    \n",
    "    for t in tqdm(range(n)):\n",
    "        y_t = t_y_dict[t]\n",
    "        H_xt = t_Hx_dict[t]\n",
    "        H_xt_trans = t_Hx_trans_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        R_hat_sum_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_em(mu, R, y_t, H_xt, H_xt_trans, H_yt, H_yt_trans)\n",
    "        \n",
    "        R_hat_sum += R_hat_sum_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R_hat_sum / n\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)    \n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 254/137328 [00:00<01:52, 1216.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1588.54it/s]\n",
      "  0%|          | 133/137328 [00:00<01:43, 1322.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.37606558]]\n",
      "normalized log_p: -inf\n",
      "convergence gap: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:29<00:00, 1539.10it/s]\n",
      "  0%|          | 132/137328 [00:00<01:44, 1311.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.07910104]]\n",
      "normalized log_p: [[-101.37606558]]\n",
      "convergence gap: [[0.29696454]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:29<00:00, 1535.26it/s]\n",
      "  0%|          | 109/137328 [00:00<02:05, 1089.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.92736468]]\n",
      "normalized log_p: [[-101.07910104]]\n",
      "convergence gap: [[0.15173636]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1554.14it/s]\n",
      "  0%|          | 156/137328 [00:00<01:28, 1553.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.83160767]]\n",
      "normalized log_p: [[-100.92736468]]\n",
      "convergence gap: [[0.09575701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1556.88it/s]\n",
      "  0%|          | 132/137328 [00:00<01:44, 1315.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.76501937]]\n",
      "normalized log_p: [[-100.83160767]]\n",
      "convergence gap: [[0.0665883]]\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1494.36it/s]\n",
      "  0%|          | 157/137328 [00:00<01:27, 1562.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.71663616]]\n",
      "normalized log_p: [[-100.76501937]]\n",
      "convergence gap: [[0.04838321]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1514.79it/s]\n",
      "  0%|          | 169/137328 [00:00<01:21, 1688.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.68061666]]\n",
      "normalized log_p: [[-100.71663616]]\n",
      "convergence gap: [[0.03601951]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:22<00:00, 1663.21it/s]\n",
      "  0%|          | 167/137328 [00:00<01:22, 1668.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.65335758]]\n",
      "normalized log_p: [[-100.68061666]]\n",
      "convergence gap: [[0.02725908]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:22<00:00, 1669.91it/s]\n",
      "  0%|          | 167/137328 [00:00<01:22, 1661.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.63248001]]\n",
      "normalized log_p: [[-100.65335758]]\n",
      "convergence gap: [[0.02087757]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:23<00:00, 1649.45it/s]\n",
      "  0%|          | 162/137328 [00:00<01:25, 1612.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.61634676]]\n",
      "normalized log_p: [[-100.63248001]]\n",
      "convergence gap: [[0.01613325]]\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1591.01it/s]\n",
      "  0%|          | 139/137328 [00:00<01:39, 1384.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.60379461]]\n",
      "normalized log_p: [[-100.61634676]]\n",
      "convergence gap: [[0.01255214]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:27<00:00, 1562.72it/s]\n",
      "  0%|          | 142/137328 [00:00<01:36, 1419.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.59397571]]\n",
      "normalized log_p: [[-100.60379461]]\n",
      "convergence gap: [[0.0098189]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1546.74it/s]\n",
      "  0%|          | 67/137328 [00:00<03:25, 668.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5862597]]\n",
      "normalized log_p: [[-100.59397571]]\n",
      "convergence gap: [[0.00771601]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:34<00:00, 1458.94it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1589.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.58017111]]\n",
      "normalized log_p: [[-100.5862597]]\n",
      "convergence gap: [[0.00608859]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1511.51it/s]\n",
      "  0%|          | 160/137328 [00:00<01:25, 1595.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5753476]]\n",
      "normalized log_p: [[-100.58017111]]\n",
      "convergence gap: [[0.0048235]]\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:32<00:00, 1480.77it/s]\n",
      "  0%|          | 156/137328 [00:00<01:28, 1556.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57151119]]\n",
      "normalized log_p: [[-100.5753476]]\n",
      "convergence gap: [[0.00383642]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1501.09it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1584.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56844755]]\n",
      "normalized log_p: [[-100.57151119]]\n",
      "convergence gap: [[0.00306364]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:33<00:00, 1472.71it/s]\n",
      "  0%|          | 150/137328 [00:00<01:31, 1499.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56599094]]\n",
      "normalized log_p: [[-100.56844755]]\n",
      "convergence gap: [[0.00245661]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:26<00:00, 1581.36it/s]\n",
      "  0%|          | 142/137328 [00:00<01:36, 1415.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56401278]]\n",
      "normalized log_p: [[-100.56599094]]\n",
      "convergence gap: [[0.00197815]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:32<00:00, 1486.95it/s]\n",
      "  0%|          | 144/137328 [00:00<01:35, 1433.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56241312]]\n",
      "normalized log_p: [[-100.56401278]]\n",
      "convergence gap: [[0.00159966]]\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:28<00:00, 1552.10it/s]\n",
      "  0%|          | 317/137328 [00:00<01:27, 1572.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.561114]]\n",
      "normalized log_p: [[-100.56241312]]\n",
      "convergence gap: [[0.00129912]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:29<00:00, 1536.28it/s]\n",
      "  0%|          | 159/137328 [00:00<01:26, 1582.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56005448]]\n",
      "normalized log_p: [[-100.561114]]\n",
      "convergence gap: [[0.00105952]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1517.85it/s]\n",
      "  0%|          | 153/137328 [00:00<01:29, 1526.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55918673]]\n",
      "normalized log_p: [[-100.56005448]]\n",
      "convergence gap: [[0.00086775]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1505.32it/s]\n",
      "  0%|          | 155/137328 [00:00<01:28, 1544.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55847312]]\n",
      "normalized log_p: [[-100.55918673]]\n",
      "convergence gap: [[0.00071361]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:31<00:00, 1498.94it/s]\n",
      "  0%|          | 110/137328 [00:00<02:05, 1097.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55788391]]\n",
      "normalized log_p: [[-100.55847312]]\n",
      "convergence gap: [[0.00058921]]\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:30<00:00, 1514.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5573955]]\n",
      "normalized log_p: [[-100.55788391]]\n",
      "convergence gap: [[0.00048841]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float64)\n",
    "\n",
    "for i in range(30):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = expectation_maximization(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print('normalized log_p_hat:', (log_p_hat/n).numpy())\n",
    "    print('normalized log_p:', (log_p/n).numpy())\n",
    "    print('convergence gap:', (log_p_hat/n - log_p/n).numpy())\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 iterations, ~39 min\n",
    "np.save('results/em_mu.npy', mu_hat)\n",
    "np.save('results/em_R.npy', R_hat)\n",
    "np.save('results/em_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McMichael’s Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans):\n",
    "    # for R estimation\n",
    "    R_yt = H_yt @ R @ H_yt_trans\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    mu_yt = tf.matmul(H_yt, mu)\n",
    "    log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "\n",
    "    # for mu estimation\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(y_t - mu_yt) @ R_yt_inv @ (y_t - mu_yt) + k*LOG_2PI)\n",
    "    \n",
    "    return log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "\n",
    "    for t in tqdm(range(n)):\n",
    "        y_t = t_y_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = \\\n",
    "            run_graph_mcmichael(mu, R, y_t, H_yt, H_yt_trans)\n",
    "        \n",
    "        log_p_gradient += log_p_gradient_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 165/137328 [00:00<01:23, 1649.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2210.07it/s]\n",
      "  0%|          | 193/137328 [00:00<01:11, 1927.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.37606558]]\n",
      "normalized log_p: -inf\n",
      "convergence gap: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2186.89it/s]\n",
      "  0%|          | 196/137328 [00:00<01:10, 1947.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.15033828]]\n",
      "normalized log_p: [[-101.37606558]]\n",
      "convergence gap: [[0.2257273]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2178.72it/s]\n",
      "  0%|          | 219/137328 [00:00<01:02, 2186.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-101.0176644]]\n",
      "normalized log_p: [[-101.15033828]]\n",
      "convergence gap: [[0.13267387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2239.03it/s]\n",
      "  0%|          | 205/137328 [00:00<01:07, 2044.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.92620553]]\n",
      "normalized log_p: [[-101.0176644]]\n",
      "convergence gap: [[0.09145888]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2183.10it/s]\n",
      "  0%|          | 196/137328 [00:00<01:09, 1959.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.85833264]]\n",
      "normalized log_p: [[-100.92620553]]\n",
      "convergence gap: [[0.06787289]]\n",
      "iteration: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2281.33it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2133.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.80569404]]\n",
      "normalized log_p: [[-100.85833264]]\n",
      "convergence gap: [[0.0526386]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2246.61it/s]\n",
      "  0%|          | 197/137328 [00:00<01:09, 1964.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.76380998]]\n",
      "normalized log_p: [[-100.80569404]]\n",
      "convergence gap: [[0.04188405]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2264.31it/s]\n",
      "  0%|          | 204/137328 [00:00<01:07, 2039.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.72994344]]\n",
      "normalized log_p: [[-100.76380998]]\n",
      "convergence gap: [[0.03386655]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2270.03it/s]\n",
      "  0%|          | 216/137328 [00:00<01:03, 2151.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.7022525]]\n",
      "normalized log_p: [[-100.72994344]]\n",
      "convergence gap: [[0.02769093]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2276.62it/s]\n",
      "  0%|          | 199/137328 [00:00<01:08, 1988.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.67941999]]\n",
      "normalized log_p: [[-100.7022525]]\n",
      "convergence gap: [[0.02283252]]\n",
      "iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2270.50it/s]\n",
      "  0%|          | 204/137328 [00:00<01:07, 2037.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.66046803]]\n",
      "normalized log_p: [[-100.67941999]]\n",
      "convergence gap: [[0.01895195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2164.01it/s]\n",
      "  0%|          | 210/137328 [00:00<01:05, 2099.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.64465236]]\n",
      "normalized log_p: [[-100.66046803]]\n",
      "convergence gap: [[0.01581567]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2303.04it/s]\n",
      "  0%|          | 237/137328 [00:00<00:57, 2368.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.63139579]]\n",
      "normalized log_p: [[-100.64465236]]\n",
      "convergence gap: [[0.01325658]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2268.23it/s]\n",
      "  0%|          | 191/137328 [00:00<01:12, 1903.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.62024378]]\n",
      "normalized log_p: [[-100.63139579]]\n",
      "convergence gap: [[0.01115201]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2250.48it/s]\n",
      "  0%|          | 230/137328 [00:00<00:59, 2292.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.6108337]]\n",
      "normalized log_p: [[-100.62024378]]\n",
      "convergence gap: [[0.00941008]]\n",
      "iteration: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2329.22it/s]\n",
      "  0%|          | 237/137328 [00:00<00:58, 2362.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.60287292]]\n",
      "normalized log_p: [[-100.6108337]]\n",
      "convergence gap: [[0.00796078]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2312.22it/s]\n",
      "  0%|          | 196/137328 [00:00<01:10, 1956.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.59612306]]\n",
      "normalized log_p: [[-100.60287292]]\n",
      "convergence gap: [[0.00674986]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2213.59it/s]\n",
      "  0%|          | 208/137328 [00:00<01:06, 2075.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.59038839]]\n",
      "normalized log_p: [[-100.59612306]]\n",
      "convergence gap: [[0.00573467]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2239.23it/s]\n",
      "  0%|          | 238/137328 [00:00<00:57, 2377.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.58550713]]\n",
      "normalized log_p: [[-100.59038839]]\n",
      "convergence gap: [[0.00488125]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2313.85it/s]\n",
      "  0%|          | 237/137328 [00:00<00:57, 2367.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.58134493]]\n",
      "normalized log_p: [[-100.58550713]]\n",
      "convergence gap: [[0.0041622]]\n",
      "iteration: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2342.53it/s]\n",
      "  0%|          | 237/137328 [00:00<00:57, 2366.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57778972]]\n",
      "normalized log_p: [[-100.58134493]]\n",
      "convergence gap: [[0.00355521]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2272.12it/s]\n",
      "  0%|          | 204/137328 [00:00<01:07, 2031.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57474776]]\n",
      "normalized log_p: [[-100.57778972]]\n",
      "convergence gap: [[0.00304196]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2229.80it/s]\n",
      "  0%|          | 234/137328 [00:00<00:58, 2338.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.57214044]]\n",
      "normalized log_p: [[-100.57474776]]\n",
      "convergence gap: [[0.00260732]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2192.80it/s]\n",
      "  0%|          | 236/137328 [00:00<00:58, 2358.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56990174]]\n",
      "normalized log_p: [[-100.57214044]]\n",
      "convergence gap: [[0.0022387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2306.11it/s]\n",
      "  0%|          | 239/137328 [00:00<00:57, 2383.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5679761]]\n",
      "normalized log_p: [[-100.56990174]]\n",
      "convergence gap: [[0.00192564]]\n",
      "iteration: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:00<00:00, 2272.78it/s]\n",
      "  0%|          | 237/137328 [00:00<00:57, 2367.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56631673]]\n",
      "normalized log_p: [[-100.5679761]]\n",
      "convergence gap: [[0.00165937]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2315.30it/s]\n",
      "  0%|          | 224/137328 [00:00<01:01, 2237.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56488416]]\n",
      "normalized log_p: [[-100.56631673]]\n",
      "convergence gap: [[0.00143256]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2347.74it/s]\n",
      "  0%|          | 238/137328 [00:00<00:57, 2379.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5636451]]\n",
      "normalized log_p: [[-100.56488416]]\n",
      "convergence gap: [[0.00123906]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:58<00:00, 2354.25it/s]\n",
      "  0%|          | 240/137328 [00:00<00:57, 2390.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56257138]]\n",
      "normalized log_p: [[-100.5636451]]\n",
      "convergence gap: [[0.00107372]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [00:59<00:00, 2289.45it/s]\n",
      "  0%|          | 227/137328 [00:00<01:00, 2257.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56163917]]\n",
      "normalized log_p: [[-100.56257138]]\n",
      "convergence gap: [[0.00093221]]\n",
      "iteration: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2207.86it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2136.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56082829]]\n",
      "normalized log_p: [[-100.56163917]]\n",
      "convergence gap: [[0.00081088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:03<00:00, 2163.17it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2131.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.56012163]]\n",
      "normalized log_p: [[-100.56082829]]\n",
      "convergence gap: [[0.00070667]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2194.76it/s]\n",
      "  0%|          | 212/137328 [00:00<01:04, 2118.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55950462]]\n",
      "normalized log_p: [[-100.56012163]]\n",
      "convergence gap: [[0.00061701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:02<00:00, 2214.82it/s]\n",
      "  0%|          | 214/137328 [00:00<01:04, 2134.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.5589649]]\n",
      "normalized log_p: [[-100.55950462]]\n",
      "convergence gap: [[0.00053972]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:01<00:00, 2224.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: [[-100.55849192]]\n",
      "normalized log_p: [[-100.5589649]]\n",
      "convergence gap: [[0.00047298]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float64)\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print('normalized log_p_hat:', (log_p_hat/n).numpy())\n",
    "    print('normalized log_p:', (log_p/n).numpy())\n",
    "    print('convergence gap:', (log_p_hat/n - log_p/n).numpy())\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 iterations, ~35 min\n",
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for t in tqdm(range(n)):\n",
    "        movie_ids_t = t_movie_ids_labels_dict[t]\n",
    "        labels_t = t_labels_dict[t]\n",
    "\n",
    "        # calculate X_t_hat\n",
    "        y_t = t_y_dict[t]\n",
    "        H_xt = t_Hx_dict[t]\n",
    "        H_xt_trans = t_Hx_trans_dict[t]\n",
    "        H_yt = t_Hy_dict[t]\n",
    "        H_yt_trans = t_Hy_trans_dict[t]\n",
    "        \n",
    "        R_xt = H_xt @ R @ H_xt_trans\n",
    "        R_yt = H_yt @ R @ H_yt_trans\n",
    "        R_yt_inv = tf.linalg.inv(R_yt)\n",
    "        R_xtyt = H_xt @ R @ H_yt_trans\n",
    "        \n",
    "        mu_yt = tf.matmul(H_yt, mu)\n",
    "        mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "        X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "        \n",
    "        # clip ratings\n",
    "        predictions_t = tf.matmul(H_xt_trans, X_t_hat).numpy()[movie_ids_t-1]\n",
    "        predictions_t = np.clip(predictions_t, 1, 5)\n",
    "        \n",
    "        # accumulate square_error and l\n",
    "        square_error += tf.matmul(tf.transpose(labels_t - predictions_t), labels_t - predictions_t)\n",
    "        l += len(labels_t)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [02:02<00:00, 1125.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07507623]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_mu = np.load('results/em_mu.npy')\n",
    "em_R = np.load('results/em_R.npy')\n",
    "rmse = evaluate(em_mu, em_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137328/137328 [01:56<00:00, 1178.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07510565]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
