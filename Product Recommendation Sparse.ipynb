{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmkfRu5134RF"
   },
   "source": [
    "# Product Recommendation\n",
    "Reference: [https://ieeexplore.ieee.org/document/5430993](https://www2.seas.gwu.edu/~simhaweb/champalg/cf/papers/wroberts.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FS5apXib34RG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops import *\n",
    "from tensorflow.raw_ops import SparseMatrixAdd, SparseMatrixMatMul, SparseMatrixSparseMatMul, SparseMatrixZeros\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ar29zUBM34RK",
    "outputId": "6177874f-8603-4e3f-da60-2bb609e02fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "gt49E_ALZ3GX",
    "outputId": "5cd0b237-215c-4377-c6b8-339176492f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 27 04:08:56 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   69C    P8    14W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHkz4VQV34RO"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3GX0q_If34RO"
   },
   "outputs": [],
   "source": [
    "Y_data = pd.read_csv('Y.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "P_data = pd.read_csv('P.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)\n",
    "\n",
    "# Y_data_full = pd.read_csv('Y_full.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # training data\n",
    "# P_data_full = pd.read_csv('P_full.csv', header=None, names=['Rating','Movie','User'], dtype=np.int32) # test data ('probe-set' mentioned in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "jIElYz6n34RR",
    "outputId": "4b2e4782-f708-4655-ece7-7e713edeac4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       5      2     1\n",
       "1       4      7     1\n",
       "2       4      8     1\n",
       "3       4     11     1\n",
       "4       4     12     1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  Movie  User\n",
       "0       3      6     1\n",
       "1       5     96     1\n",
       "2       3      1     2\n",
       "3       3     33     3\n",
       "4       5     42     4"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Y_data.head())\n",
    "display(P_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zVHMQ8gY34RU",
    "outputId": "d122c730-c7f4-478f-db82-78aee93f4d41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3399874, 3), (189699, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape, P_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "MCmeGkgl34RX",
    "outputId": "5a6a3332-5003-4a8b-9ff6-ce4ed2bd701e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100 137328\n",
      "5 100 137328\n"
     ]
    }
   ],
   "source": [
    "print(Y_data['Rating'].unique().max(), Y_data['Movie'].unique().max(), Y_data['User'].unique().max())\n",
    "print(P_data['Rating'].unique().max(), P_data['Movie'].unique().max(), P_data['User'].unique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_80ytphB34Ra",
    "outputId": "49250501-49c3-49e6-c48e-9abeaf931a2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 137328)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = Y_data['Movie'].unique().max(), Y_data['User'].unique().max()\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pO_vr5z334Rk"
   },
   "outputs": [],
   "source": [
    "def generate_indices_pair_list(data):\n",
    "    user_id = 1\n",
    "    indices_list = list()\n",
    "    for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        if row['User'] != user_id:\n",
    "            user_id = row['User']\n",
    "            indices_list.append(index - 1)\n",
    "\n",
    "    indices_pair_list = list()\n",
    "    for index_ending in indices_list:\n",
    "        if index_ending == indices_list[0]:\n",
    "            indices_pair_list.append((0, index_ending))\n",
    "        else:\n",
    "            index_beginning = indices_pair_list[-1][1] + 1\n",
    "            indices_pair_list.append((index_beginning, index_ending))\n",
    "    return indices_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "hXhR9fwaoJXo",
    "outputId": "a7caab06-6255-41fd-ab18-9749bc3422e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3399874/3399874 [03:35<00:00, 15785.70it/s]\n",
      "100%|██████████| 189699/189699 [00:12<00:00, 15308.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_pair_list_Y_data = generate_indices_pair_list(Y_data)\n",
    "indices_pair_list_P_data = generate_indices_pair_list(P_data)\n",
    "len(indices_pair_list_Y_data) == len(indices_pair_list_P_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CUBYeVaK34Rt",
    "outputId": "7c5b7c30-fb32-4049-ce6a-a187baebd8e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [04:46<00:00, 478.72it/s]\n"
     ]
    }
   ],
   "source": [
    "data_preprocessed = list()\n",
    "for index_pair_Y_data, index_pair_P_data in tqdm(zip(indices_pair_list_Y_data, indices_pair_list_P_data), total=len(indices_pair_list_Y_data)):\n",
    "    Y_data_t = Y_data.loc[index_pair_Y_data[0]:index_pair_Y_data[1], :]\n",
    "    \n",
    "    movie_ids_t_indices = (Y_data_t['Movie'].values - 1).astype(np.int64)\n",
    "    movie_ids_t_indices_deleted = np.setdiff1d(np.arange(k, dtype=np.int64), movie_ids_t_indices)\n",
    "    \n",
    "    H_yt_st_indices = np.vstack((np.arange(movie_ids_t_indices.shape[0]), movie_ids_t_indices)).T\n",
    "    H_xt_st_indices = np.vstack((np.arange(movie_ids_t_indices_deleted.shape[0]), movie_ids_t_indices_deleted)).T\n",
    "    z_t_st_indices = np.vstack((movie_ids_t_indices, np.zeros(movie_ids_t_indices.shape[0], dtype=np.int64))).T\n",
    "        \n",
    "    H_yt_st = tf.SparseTensor(indices=H_yt_st_indices, values=np.ones(H_yt_st_indices.shape[0], dtype=np.float32), dense_shape=[H_yt_st_indices.shape[0], k])\n",
    "    H_xt_st = tf.SparseTensor(indices=H_xt_st_indices, values=np.ones(H_xt_st_indices.shape[0], dtype=np.float32), dense_shape=[H_xt_st_indices.shape[0], k])\n",
    "    z_t_st = tf.SparseTensor(indices=z_t_st_indices, values=Y_data_t['Rating'].values.astype(np.float32), dense_shape=[k, 1])\n",
    "\n",
    "    H_yt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_yt_st.indices, values=H_yt_st.values, dense_shape=H_yt_st.dense_shape)\n",
    "    H_xt_sm = sparse_tensor_to_csr_sparse_matrix(indices=H_xt_st.indices, values=H_xt_st.values, dense_shape=H_xt_st.dense_shape)\n",
    "    z_t_sm = sparse_tensor_to_csr_sparse_matrix(indices=z_t_st.indices, values=z_t_st.values, dense_shape=z_t_st.dense_shape)\n",
    "    \n",
    "    y_t = csr_sparse_matrix_to_dense(SparseMatrixSparseMatMul(a=H_yt_sm, b=z_t_sm, type=tf.float32), tf.float32)\n",
    "    k_t = tf.constant(H_yt_st_indices.shape[0], dtype=tf.float32)\n",
    "\n",
    "    P_data_t = P_data.loc[index_pair_P_data[0]:index_pair_P_data[1], :]\n",
    "    movie_ids_t_P_data = P_data_t['Movie'].values\n",
    "    ratings_t_P_data = tf.expand_dims(P_data_t['Rating'].values.astype(np.float32), axis=1)\n",
    "      \n",
    "    data_preprocessed.append((H_yt_sm, H_xt_sm, y_t, k_t, movie_ids_t_P_data, ratings_t_P_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hCCgj-eN34R2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2reL7Zyx34R4"
   },
   "source": [
    "## Initialization\n",
    "\n",
    "$\\mu$ has 1 type available\n",
    "\n",
    "$N = \\sum_{t=1}^{n}H_{y_t}'H_{y_t}$\n",
    "\n",
    "$\\hat{\\mu}^0 = N^{-1}\\sum_{t-1}^{n}H_{y_t}'y_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4GXz93Hq34R7",
    "outputId": "c534230e-6fac-4836-dfe3-ad3fc030c697"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [01:27<00:00, 1564.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# initial estimate of mu\n",
    "N_sm = SparseMatrixZeros(dense_shape=(k, k), type=tf.float32)\n",
    "H_yty_t = 0\n",
    "\n",
    "for (H_yt_sm, H_xt_sm, y_t, k_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "    N_sm = SparseMatrixAdd(a=N_sm, b=SparseMatrixSparseMatMul(a=H_yt_sm, b=H_yt_sm, type=tf.float32, transpose_a=True), alpha=1.0, beta=1.0)\n",
    "    H_yty_t += SparseMatrixMatMul(a=H_yt_sm, b=y_t, transpose_a=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "xIVUEfFNKmWo",
    "outputId": "2cd53238-b49a-49c3-af40-42916a09c516"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
       "array([[3.4526653, 3.5767686, 3.2878866, 3.9047875, 3.7903547, 3.4441562,\n",
       "        3.190684 , 4.5283504, 3.8201292, 3.6159503, 3.4038272, 3.8372512,\n",
       "        4.076039 , 4.228367 , 3.3539274, 4.0645275, 3.7211962, 3.4870086,\n",
       "        4.1638894, 3.4097998, 3.86926  , 3.435835 , 3.2032225, 4.084879 ,\n",
       "        3.2320046, 3.886682 , 4.331895 , 4.383559 , 4.316363 , 3.8659174,\n",
       "        4.339757 , 3.8914747, 3.7002807, 3.3624778, 4.3289886, 4.0670323,\n",
       "        4.56922  , 3.771041 , 3.6858559, 3.8453238, 4.345388 , 3.9099529,\n",
       "        3.3994992, 3.6078188, 3.9626696, 4.143861 , 3.4072049, 3.7040153,\n",
       "        4.0034695, 4.6428022, 3.216206 , 3.7723858, 4.265651 , 4.4537544,\n",
       "        3.8384895, 3.793742 , 3.76288  , 3.8869822, 3.8004174, 4.346952 ,\n",
       "        3.8046887, 3.8462136, 3.6412156, 3.2722168, 3.4232938, 3.7163155,\n",
       "        3.2069893, 4.4541044, 4.265392 , 3.8610888, 4.483009 , 4.3621464,\n",
       "        3.5388138, 4.1171074, 3.8946686, 3.3607738, 4.179405 , 3.5793724,\n",
       "        3.63975  , 3.9759395, 3.7506986, 3.8211102, 4.034035 , 3.9582725,\n",
       "        3.4913766, 3.4741821, 3.8214757, 3.6429584, 3.4742756, 3.6389303,\n",
       "        3.4526339, 3.504752 , 4.3672986, 4.361775 , 4.0114975, 4.1923757,\n",
       "        3.4806535, 3.8585596, 3.8025846, 3.387365 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ith diagonal element of N equals the total number of ratings of the ith product.\n",
    "N_inv = tf.linalg.inv(csr_sparse_matrix_to_dense(N_sm, tf.float32))\n",
    "mu_hat0 = tf.matmul(N_inv, H_yty_t)\n",
    "tf.transpose(mu_hat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vja1fJxr34SL"
   },
   "source": [
    "R has 4 types available\n",
    "\n",
    "$R_{1} = I$\n",
    "\n",
    "$R_{2} = N^{-1}diag(S)$\n",
    "\n",
    "$R_{3} = diag(S)^{-1/2}Sdiag(S)^{-1/2}$\n",
    "\n",
    "$R_{4} = N^{-1/2}SN^{-1/2}$\n",
    "\n",
    "where $S = \\sum_{t=1}^{n}H_{y_{t}}'(y_t - H_{y_{t}}\\hat{\\mu}^0)(y_t - H_{y_{t}}\\hat{\\mu}^0)'H_{y_{t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "hCmQxlgc34SL",
    "outputId": "bbff4626-553c-4429-dd74-adb55359203e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial estimates of R (4 types available)\n",
    "R_hat0_1 = tf.eye(k, dtype=tf.float32)\n",
    "R_hat0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aKGDb-C3tZZI",
    "outputId": "7a45cd6e-e163-490c-e492-3c8802108dea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [00:26<00:00, 5130.41it/s]\n"
     ]
    }
   ],
   "source": [
    "S = 0\n",
    "for (H_yt_sm, H_xt_sm, y_t, k_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "    Hytmu_hat0 = SparseMatrixMatMul(a=H_yt_sm, b=mu_hat0)\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=y_t - Hytmu_hat0, transpose_a=True)\n",
    "    S += tf.matmul(intermediate_result, intermediate_result, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "wDgAbOwV34SW",
    "outputId": "e7f7266f-ec32-4056-a405-5daa14885c05",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[1.724364  , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.94218737, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.4365153 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.1832287 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.0349729 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.2620498 ]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diag_S is the diagonal matrix consisting of the diagonal elements of S\n",
    "diag_S = tf.linalg.diag(tf.linalg.tensor_diag_part(S))\n",
    "R_hat0_2 = tf.matmul(N_inv, diag_S)\n",
    "R_hat0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "z59PFlrGOaNI",
    "outputId": "28dd86e6-5cac-4f41-eb93-df9ef6fca588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[ 1.        ,  0.07418733, -0.01158332, ..., -0.01462825,\n",
       "        -0.02215315, -0.0184503 ],\n",
       "       [ 0.07418733,  0.99999994,  0.03674517, ...,  0.02561875,\n",
       "         0.03563373,  0.0392758 ],\n",
       "       [-0.01158332,  0.03674516,  0.9999999 , ...,  0.1095439 ,\n",
       "         0.12823555,  0.15562423],\n",
       "       ...,\n",
       "       [-0.01462825,  0.02561875,  0.1095439 , ...,  1.0000001 ,\n",
       "         0.19780138,  0.15164192],\n",
       "       [-0.02215315,  0.03563373,  0.12823555, ...,  0.1978014 ,\n",
       "         1.0000001 ,  0.18996929],\n",
       "       [-0.0184503 ,  0.0392758 ,  0.15562423, ...,  0.15164192,\n",
       "         0.18996929,  1.0000001 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_3 is not a good initializer when rating variances are far from one\n",
    "diag_S_inv = tf.linalg.inv(diag_S)\n",
    "R_hat0_3 = tf.linalg.sqrtm(diag_S_inv) @ S @ tf.linalg.sqrtm(diag_S_inv)\n",
    "R_hat0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "E1VHBBE8OGN7",
    "outputId": "fb53d9bc-3bc9-4f4c-e099-503dd198b916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100), dtype=float32, numpy=\n",
       "array([[ 1.724364  ,  0.09456117, -0.01823068, ..., -0.02089494,\n",
       "        -0.02959474, -0.02721799],\n",
       "       [ 0.09456117,  0.94218737,  0.04274881, ...,  0.0270496 ,\n",
       "         0.03518798,  0.0428284 ],\n",
       "       [-0.01823068,  0.04274881,  1.4365153 , ...,  0.14281628,\n",
       "         0.15636086,  0.20954177],\n",
       "       ...,\n",
       "       [-0.02089494,  0.0270496 ,  0.14281628, ...,  1.1832289 ,\n",
       "         0.21889113,  0.18530701],\n",
       "       [-0.02959474,  0.03518798,  0.15636086, ...,  0.21889113,\n",
       "         1.0349729 ,  0.21711312],\n",
       "       [-0.02721799,  0.04282841,  0.20954175, ...,  0.18530701,\n",
       "         0.21711312,  1.2620498 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_hat0_4 = tf.matmul(tf.linalg.sqrtm(N_inv), tf.matmul(S, tf.linalg.sqrtm(N_inv)))\n",
    "R_hat0_4 = tf.linalg.sqrtm(N_inv) @ S @ tf.linalg.sqrtm(N_inv)\n",
    "R_hat0_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_VJkEdd34Sc"
   },
   "source": [
    "## McMichael’s Algorithm\n",
    "\n",
    "1. $\\hat{R}^{i+1} = \\hat{R}^{i} + \\gamma \\hat{R}^{i} \\bigg(\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} \\bigg) \\hat{R}^{i}$ <br />\n",
    "where $\\frac{d}{dR} \\log{p}(y^n; \\mu, R)|_{R = \\hat{R}^i} = -\\frac{1}{2} \\sum_{t=1}^{n} H_{y_t}' \\Big(\\big(R_{y_t}^{i}\\big)^{-1} - \\big(R_{y_t}^{i}\\big)^{-1} (y_t - \\mu_{y_t}) (y_t - \\mu_{y_t})' \\big(R_{y_t}^{i}\\big)^{-1}\\Big) H_{y_t}$\n",
    "\n",
    "2. $\\hat{\\mu} = \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}H_{y_t}\\big)^{-1} \\big(\\sum_{t=1}^{n}H_{y_t}'R_{y_t}^{-1}y_t\\big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6IVQrbdd34Sc"
   },
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_mcmichael(mu, R, y_t, H_yt_sm, k_t):\n",
    "    # for R estimation\n",
    "    # R_yt = H_yt @ R @ H_yt_trans\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=R)\n",
    "    R_yt = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "\n",
    "    R_yt_det = tf.linalg.det(R_yt)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    # mu_yt = tf.matmul(H_yt, mu)\n",
    "    mu_yt = SparseMatrixMatMul(a=H_yt_sm, b=mu)\n",
    "    yt_minus_mu_yt = y_t - mu_yt\n",
    "\n",
    "    # log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "    intermediate_result_1 = R_yt_inv @ yt_minus_mu_yt      \n",
    "    intermediate_result_2 = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv - tf.matmul(intermediate_result_1, intermediate_result_1, transpose_b=True), transpose_a=True)\n",
    "    log_p_gradient_part = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result_2, transpose_a=True, transpose_b=True, transpose_output=True)\n",
    "\n",
    "    # for mu estimation\n",
    "    # Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv, transpose_a=True, transpose_b=True, transpose_output=True)\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum_part = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_a=True)\n",
    "    # Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "    Hyt_trans_Ryt_inv_yt_sum_part = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv @ y_t, transpose_a=True)\n",
    "    \n",
    "    # for log likelihood calculation\n",
    "    log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(yt_minus_mu_yt) @ R_yt_inv @ (yt_minus_mu_yt) + k_t*LOG_2PI)\n",
    "    \n",
    "    return log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5E-PMb4w34Se"
   },
   "outputs": [],
   "source": [
    "def mcmichael(mu, R):\n",
    "    gamma = 0.00001\n",
    "    Hyt_trans_Ryt_inv_Hyt_sum = 0\n",
    "    Hyt_trans_Ryt_inv_yt_sum = 0\n",
    "    log_p_gradient = 0\n",
    "    log_p_hat = 0\n",
    "\n",
    "    for (H_yt_sm, H_xt_sm, y_t, k_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        # log_p_gradient_part, Hyt_trans_Ryt_inv_Hyt_sum_part, Hyt_trans_Ryt_inv_yt_sum_part, log_p_hat_part = run_graph_mcmichael(mu, R, y_t, H_yt_sm, k_t)\n",
    "\n",
    "        # for R estimation\n",
    "        # R_yt = H_yt @ R @ H_yt_trans\n",
    "        intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=R)\n",
    "        R_yt = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "\n",
    "        R_yt_det = tf.linalg.det(R_yt)\n",
    "        R_yt_inv = tf.linalg.inv(R_yt)\n",
    "        # mu_yt = tf.matmul(H_yt, mu)\n",
    "        mu_yt = SparseMatrixMatMul(a=H_yt_sm, b=mu)\n",
    "        yt_minus_mu_yt = y_t - mu_yt\n",
    "\n",
    "        # log_p_gradient_part = H_yt_trans @ (R_yt_inv - R_yt_inv @ (y_t - mu_yt) @ tf.transpose(y_t - mu_yt) @ R_yt_inv) @ H_yt\n",
    "        intermediate_result_1 = R_yt_inv @ yt_minus_mu_yt      \n",
    "        intermediate_result_2 = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv - tf.matmul(intermediate_result_1, intermediate_result_1, transpose_b=True), transpose_a=True)\n",
    "        log_p_gradient_part = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result_2, transpose_a=True, transpose_b=True, transpose_output=True)\n",
    "\n",
    "        # for mu estimation\n",
    "        # Hyt_trans_Ryt_inv_Hyt_sum_part = H_yt_trans @ R_yt_inv @ H_yt\n",
    "        intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv, transpose_a=True, transpose_b=True, transpose_output=True)\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum_part = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_a=True)\n",
    "        # Hyt_trans_Ryt_inv_yt_sum_part = H_yt_trans @ R_yt_inv @ y_t\n",
    "        Hyt_trans_Ryt_inv_yt_sum_part = SparseMatrixMatMul(a=H_yt_sm, b=R_yt_inv @ y_t, transpose_a=True)\n",
    "        \n",
    "        # for log likelihood calculation\n",
    "        log_p_hat_part = -1/2*(tf.math.log(R_yt_det) + tf.transpose(yt_minus_mu_yt) @ R_yt_inv @ (yt_minus_mu_yt) + k_t*LOG_2PI)\n",
    "        \n",
    "        log_p_gradient += log_p_gradient_part\n",
    "        Hyt_trans_Ryt_inv_Hyt_sum += Hyt_trans_Ryt_inv_Hyt_sum_part\n",
    "        Hyt_trans_Ryt_inv_yt_sum += Hyt_trans_Ryt_inv_yt_sum_part\n",
    "        log_p_hat += log_p_hat_part\n",
    "        \n",
    "    R_hat = R + gamma*(R @ (-1/2*log_p_gradient) @ R)\n",
    "    mu_hat = tf.matmul(tf.linalg.inv(Hyt_trans_Ryt_inv_Hyt_sum), Hyt_trans_Ryt_inv_yt_sum)\n",
    "    return mu_hat, R_hat, log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "RlwupDTDQ1_u",
    "outputId": "b3fab280-f7a9-4108-c130-6a5ca633af0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/137327 [00:00<06:12, 368.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [04:43<00:00, 483.62it/s]\n",
      "  0%|          | 42/137327 [00:00<05:29, 416.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.232\n",
      "normalized log_p:     -inf\n",
      "convergence gap:      inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137327/137327 [04:42<00:00, 486.89it/s]\n",
      "  0%|          | 50/137327 [00:00<04:34, 499.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized log_p_hat: -32.007\n",
      "normalized log_p:     -32.232\n",
      "convergence gap:      0.22573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 126111/137327 [04:18<00:23, 484.05it/s]"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "mu = mu_hat0\n",
    "R = R_hat0_4\n",
    "log_p = tf.constant(-np.inf, dtype=tf.float32)\n",
    "LOG_2PI = tf.math.log(2*tf.constant(np.pi, dtype=tf.float32))\n",
    "\n",
    "for i in range(40):\n",
    "    if i % 5 == 0:\n",
    "        print(f'iteration: {i}')\n",
    "    \n",
    "    mu_hat, R_hat, log_p_hat = mcmichael(mu, R)\n",
    "    convergence_criterion = log_p_hat/n - log_p/n < delta\n",
    "    \n",
    "    print(f'normalized log_p_hat: {(log_p_hat/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'normalized log_p:     {(log_p/n).numpy().flatten()[0]:.5}')\n",
    "    print(f'convergence gap:      {(log_p_hat/n - log_p/n).numpy().flatten()[0]:.5}')\n",
    "    \n",
    "    if convergence_criterion:\n",
    "        break\n",
    "        \n",
    "    # use new estimattions for next iteration\n",
    "    mu = mu_hat\n",
    "    R = R_hat\n",
    "    log_p = log_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOaC9y5W34Si"
   },
   "outputs": [],
   "source": [
    "np.save('results/mcmichael_mu.npy', mu_hat)\n",
    "np.save('results/mcmichael_R.npy', R_hat)\n",
    "np.save('results/mcmichael_log_p.npy', log_p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQALOtIF34Sk"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "$\\epsilon^2 = \\frac{\\sum_{t=1}^{n}\\big(x_t - \\hat{X_t}\\big)'\\big(x_t - \\hat{X_t}\\big)}{\\sum_{t=1}^{n} l_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J14IrXUO34Sk"
   },
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt_sm, H_yt_sm):\n",
    "    # calculate X_t_hat\n",
    "    # R_xt = H_xt @ R @ H_xt_trans\n",
    "    # R_yt = H_yt @ R @ H_yt_trans\n",
    "    # R_yt_inv = tf.linalg.inv(R_yt)\n",
    "    # R_xtyt = H_xt @ R @ H_yt_trans\n",
    "\n",
    "    # mu_yt = tf.matmul(H_yt, mu)\n",
    "    # mu_xt = tf.matmul(H_xt, mu)\n",
    "\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_xt_sm, b=R)\n",
    "    R_xt = SparseMatrixMatMul(a=H_xt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "    \n",
    "    intermediate_result = SparseMatrixMatMul(a=H_yt_sm, b=R)\n",
    "    R_yt = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "    R_yt_inv = tf.linalg.inv(R_yt)\n",
    "\n",
    "    intermediate_result = SparseMatrixMatMul(a=H_xt_sm, b=R)\n",
    "    R_xtyt = SparseMatrixMatMul(a=H_yt_sm, b=intermediate_result, transpose_b=True, transpose_output=True)\n",
    "\n",
    "    mu_yt = SparseMatrixMatMul(a=H_yt_sm, b=mu)\n",
    "    mu_xt = SparseMatrixMatMul(a=H_xt_sm, b=mu)\n",
    "\n",
    "    X_t_hat = R_xtyt @ R_yt_inv @ (y_t - mu_yt) + mu_xt\n",
    "    \n",
    "    # clip ratings\n",
    "    # predictions_t = tf.gather(tf.matmul(H_xt_trans, X_t_hat), indices=movie_ids_t-1)\n",
    "    predictions_t = tf.gather(SparseMatrixMatMul(a=H_xt_sm, b=X_t_hat, transpose_a=True), indices=movie_ids_t_P_data-1)\n",
    "    predictions_t = tf.clip_by_value(predictions_t, 1, 5)\n",
    "    \n",
    "    return tf.matmul(tf.transpose(ratings_t_P_data - predictions_t), ratings_t_P_data - predictions_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1mubgMW34Sn"
   },
   "outputs": [],
   "source": [
    "def evaluate(mu, R):\n",
    "    square_error = 0\n",
    "    l = 0\n",
    "    for (H_yt_sm, H_xt_sm, y_t, k_t, movie_ids_t_P_data, ratings_t_P_data) in tqdm(data_preprocessed):\n",
    "        square_error += run_graph_square_error(mu, R, movie_ids_t_P_data, ratings_t_P_data, y_t, H_xt_sm, H_yt_sm)\n",
    "        l += len(ratings_t_P_data)\n",
    "    return np.sqrt(square_error/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m88m_IvM34Sr"
   },
   "outputs": [],
   "source": [
    "mcmichael_mu = np.load('results/mcmichael_mu.npy')\n",
    "mcmichael_R = np.load('results/mcmichael_R.npy')\n",
    "rmse = evaluate(mcmichael_mu, mcmichael_R)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTe3igOD34St"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Product Recommendation Sparse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
